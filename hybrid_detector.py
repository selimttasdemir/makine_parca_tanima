"""
Hibrit ParÃ§a TanÄ±ma Sistemi
Hem Deep Learning hem de Feature Matching kullanan akÄ±llÄ± sistem
"""

import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple
import json
import warnings

# PyTorch uyarÄ±larÄ±nÄ± bastÄ±r
warnings.filterwarnings('ignore')
warnings.filterwarnings('ignore', message='.*torch.*')

# Lazy imports
def lazy_import_torch():
    """Sadece gerektiÄŸinde torch import et"""
    import torch
    import torch.nn as nn
    from torchvision import transforms
    from PIL import Image
    return torch, nn, transforms, Image

try:
    from feature_matcher import FeatureMatchingTanima
    FEATURE_AVAILABLE = True
except ImportError:
    FEATURE_AVAILABLE = False
    print("âš ï¸  Feature matcher yÃ¼klenemedi")


class HibritTanima:
    """
    Ä°ki yÃ¶ntemi birleÅŸtiren akÄ±llÄ± tanÄ±ma sistemi:
    1. Deep Learning model varsa kullan (yÃ¼ksek doÄŸruluk)
    2. Model yoksa veya gÃ¼ven dÃ¼ÅŸÃ¼kse Feature Matching kullan
    3. Her iki sonucu birleÅŸtir (ensemble)
    """
    
    def __init__(
        self, 
        model_path=None,
        referans_klasor=None,
        guven_esik=0.7,
        mod='auto'
    ):
        """
        Args:
            model_path: EÄŸitilmiÅŸ DL model yolu
            referans_klasor: Referans gÃ¶rÃ¼ntÃ¼ler klasÃ¶rÃ¼
            guven_esik: Bu deÄŸerin altÄ±nda feature matching devreye girer
            mod: 'dl_only', 'feature_only', 'auto', 'ensemble'
        """
        self.guven_esik = guven_esik
        self.mod = mod
        
        # Deep Learning modeli
        self.dl_model = None
        self.dl_siniflar = None
        self.dl_kullanilabilir = False
        
        if model_path and Path(model_path).exists():
            self._dl_model_yukle(model_path)
        
        # Feature Matching sistemi
        self.feature_matcher = None
        self.feature_kullanilabilir = False
        
        if FEATURE_AVAILABLE and referans_klasor and Path(referans_klasor).exists():
            self.feature_matcher = FeatureMatchingTanima(referans_klasor)
            self.feature_kullanilabilir = len(self.feature_matcher.referans_veritabani) > 0
        
        # Transform lazy olacak
        self.transform = None
        
        self._sistem_durumu()
    
    def _dl_model_yukle(self, model_path):
        """Deep Learning modelini yÃ¼kle"""
        try:
            torch, nn, transforms_lib, Image_lib = lazy_import_torch()
            from train_model import MakineParcaModel
            
            checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
            self.dl_siniflar = checkpoint['classes']
            
            self.dl_model = MakineParcaModel(
                num_classes=len(self.dl_siniflar),
                pretrained=False
            )
            self.dl_model.load_state_dict(checkpoint['model_state_dict'])
            self.dl_model.eval()
            
            self.dl_kullanilabilir = True
            print(f"âœ… DL Model yÃ¼klendi: {len(self.dl_siniflar)} sÄ±nÄ±f")
            
        except Exception as e:
            print(f"âš ï¸  DL Model yÃ¼klenemedi: {e}")
            self.dl_kullanilabilir = False
    
    def _sistem_durumu(self):
        """Sistem durumunu gÃ¶ster"""
        print("\n" + "=" * 60)
        print("ğŸ¤– Hibrit TanÄ±ma Sistemi Durumu")
        print("=" * 60)
        
        if self.dl_kullanilabilir:
            print(f"âœ… Deep Learning: Aktif ({len(self.dl_siniflar)} sÄ±nÄ±f)")
        else:
            print("âŒ Deep Learning: Pasif")
        
        if self.feature_kullanilabilir:
            ref_sayisi = len(self.feature_matcher.referans_veritabani)
            print(f"âœ… Feature Matching: Aktif ({ref_sayisi} referans)")
        else:
            print("âŒ Feature Matching: Pasif")
        
        print(f"âš™ï¸  Mod: {self.mod}")
        print(f"ğŸ“Š GÃ¼ven EÅŸiÄŸi: {self.guven_esik}")
        print("=" * 60 + "\n")
    
    def _dl_tahmin(self, goruntu_path: str) -> Dict:
        """Deep Learning ile tahmin"""
        torch, nn, transforms_lib, Image_lib = lazy_import_torch()
        
        # Transform oluÅŸtur
        transform = transforms_lib.Compose([
            transforms_lib.Resize((224, 224)),
            transforms_lib.ToTensor(),
            transforms_lib.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        image = Image_lib.open(goruntu_path).convert('RGB')
        image_tensor = transform(image).unsqueeze(0)
        
        with torch.no_grad():
            outputs = self.dl_model(image_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, predicted = probabilities.max(1)
        
        predicted_class = self.dl_siniflar[predicted.item()]
        confidence_score = confidence.item()
        
        # TÃ¼m sÄ±nÄ±f olasÄ±lÄ±klarÄ±
        all_probs = {}
        for i, sinif in enumerate(self.dl_siniflar):
            all_probs[sinif] = probabilities[0][i].item()
        
        return {
            'method': 'deep_learning',
            'parca': predicted_class,
            'guven': confidence_score,
            'olasiliklar': all_probs
        }
    
    def _feature_tahmin(self, goruntu_path: str) -> Dict:
        """Feature Matching ile tahmin (Åekil analizi dahil)"""
        # Åekil analizi ile tanÄ±ma yap
        sonuclar = self.feature_matcher.tanima_yap(
            goruntu_path, 
            method='hybrid',
            sekil_analizi_kullan=True  # Åekil analizini aktifleÅŸtir
        )
        
        if not sonuclar:
            return {
                'method': 'feature_matching',
                'parca': 'bilinmiyor',
                'guven': 0.0,
                'detaylar': []
            }
        
        en_iyi = sonuclar[0]
        
        return {
            'method': 'feature_matching',
            'parca': en_iyi['parca_adi'],
            'guven': en_iyi['skor'],
            'base_skor': en_iyi.get('base_skor', en_iyi['skor']),
            'sekil_bonusu': en_iyi.get('sekil_bonusu', 0),
            'detaylar': sonuclar[:3],  # En iyi 3
            'sift_skor': en_iyi['sift_skor'],
            'histogram_skor': en_iyi['histogram_skor'],
            'hu_skor': en_iyi['hu_skor']
        }
    
    def _ensemble_tahmin(self, dl_sonuc: Dict, feature_sonuc: Dict) -> Dict:
        """Ä°ki yÃ¶ntemi birleÅŸtir"""
        # AÄŸÄ±rlÄ±klÄ± birleÅŸtirme
        dl_agirlik = 0.7  # DL daha gÃ¼venilir
        feature_agirlik = 0.3
        
        # Her parÃ§a iÃ§in toplam skor hesapla
        parca_skorlari = {}
        
        # DL skorlarÄ±
        if dl_sonuc:
            for parca, olasilik in dl_sonuc.get('olasiliklar', {}).items():
                parca_skorlari[parca] = dl_agirlik * olasilik
        
        # Feature matching skorlarÄ±
        if feature_sonuc and feature_sonuc.get('detaylar'):
            for detay in feature_sonuc['detaylar']:
                parca = detay['parca_adi']
                skor = detay['skor']
                
                if parca in parca_skorlari:
                    parca_skorlari[parca] += feature_agirlik * skor
                else:
                    parca_skorlari[parca] = feature_agirlik * skor
        
        # En yÃ¼ksek skoru bul
        if parca_skorlari:
            en_iyi_parca = max(parca_skorlari.items(), key=lambda x: x[1])
            
            return {
                'method': 'ensemble',
                'parca': en_iyi_parca[0],
                'guven': en_iyi_parca[1],
                'dl_sonuc': dl_sonuc,
                'feature_sonuc': feature_sonuc,
                'tum_skorlar': parca_skorlari
            }
        
        # Fallback
        if dl_sonuc:
            return dl_sonuc
        elif feature_sonuc:
            return feature_sonuc
        else:
            return {'method': 'none', 'parca': 'bilinmiyor', 'guven': 0.0}
    
    def tanima_yap(self, goruntu_path: str) -> Dict:
        """
        AkÄ±llÄ± tanÄ±ma yap
        
        Strateji:
        - auto: DL Ã¶nce, gÃ¼ven dÃ¼ÅŸÃ¼kse feature matching ekle
        - ensemble: Her ikisini de kullan ve birleÅŸtir
        - dl_only: Sadece deep learning
        - feature_only: Sadece feature matching
        """
        if not Path(goruntu_path).exists():
            raise FileNotFoundError(f"GÃ¶rÃ¼ntÃ¼ bulunamadÄ±: {goruntu_path}")
        
        print(f"\nğŸ” GÃ¶rÃ¼ntÃ¼ analiz ediliyor: {goruntu_path}")
        print("-" * 60)
        
        dl_sonuc = None
        feature_sonuc = None
        
        # Mod'a gÃ¶re iÅŸle
        if self.mod == 'dl_only':
            if not self.dl_kullanilabilir:
                raise ValueError("DL model yÃ¼klÃ¼ deÄŸil!")
            dl_sonuc = self._dl_tahmin(goruntu_path)
            final_sonuc = dl_sonuc
            
        elif self.mod == 'feature_only':
            if not self.feature_kullanilabilir:
                raise ValueError("Feature matching sistemi yÃ¼klÃ¼ deÄŸil!")
            feature_sonuc = self._feature_tahmin(goruntu_path)
            final_sonuc = feature_sonuc
            
        elif self.mod == 'ensemble':
            if self.dl_kullanilabilir:
                dl_sonuc = self._dl_tahmin(goruntu_path)
                print(f"  DL: {dl_sonuc['parca']} (gÃ¼ven: {dl_sonuc['guven']:.3f})")
            
            if self.feature_kullanilabilir:
                feature_sonuc = self._feature_tahmin(goruntu_path)
                print(f"  FM: {feature_sonuc['parca']} (gÃ¼ven: {feature_sonuc['guven']:.3f})")
            
            final_sonuc = self._ensemble_tahmin(dl_sonuc, feature_sonuc)
            
        else:  # auto
            # Ã–nce DL dene
            if self.dl_kullanilabilir:
                dl_sonuc = self._dl_tahmin(goruntu_path)
                print(f"  DL: {dl_sonuc['parca']} (gÃ¼ven: {dl_sonuc['guven']:.3f})")
                
                if dl_sonuc['guven'] >= self.guven_esik:
                    # Yeterince gÃ¼venli
                    final_sonuc = dl_sonuc
                else:
                    # GÃ¼ven dÃ¼ÅŸÃ¼k, feature matching ekle
                    if self.feature_kullanilabilir:
                        print("  âš ï¸  DL gÃ¼veni dÃ¼ÅŸÃ¼k, Feature Matching ekleniyor...")
                        feature_sonuc = self._feature_tahmin(goruntu_path)
                        print(f"  FM: {feature_sonuc['parca']} (gÃ¼ven: {feature_sonuc['guven']:.3f})")
                        final_sonuc = self._ensemble_tahmin(dl_sonuc, feature_sonuc)
                    else:
                        final_sonuc = dl_sonuc
            
            elif self.feature_kullanilabilir:
                # DL yok, sadece feature matching
                feature_sonuc = self._feature_tahmin(goruntu_path)
                final_sonuc = feature_sonuc
            
            else:
                raise ValueError("HiÃ§bir tanÄ±ma yÃ¶ntemi aktif deÄŸil!")
        
        print("-" * 60)
        print(f"âœ… SonuÃ§: {final_sonuc['parca'].upper()} "
              f"(gÃ¼ven: {final_sonuc['guven']:.3f}, "
              f"yÃ¶ntem: {final_sonuc['method']})\n")
        
        return final_sonuc
    
    def toplu_test(self, test_klasor: str) -> List[Dict]:
        """Bir klasÃ¶rdeki tÃ¼m gÃ¶rÃ¼ntÃ¼leri test et"""
        test_path = Path(test_klasor)
        sonuclar = []
        
        for img_path in test_path.glob('*.jpg'):
            try:
                sonuc = self.tanima_yap(str(img_path))
                sonuclar.append({
                    'dosya': img_path.name,
                    **sonuc
                })
            except Exception as e:
                print(f"âŒ Hata ({img_path.name}): {e}")
        
        for img_path in test_path.glob('*.png'):
            try:
                sonuc = self.tanima_yap(str(img_path))
                sonuclar.append({
                    'dosya': img_path.name,
                    **sonuc
                })
            except Exception as e:
                print(f"âŒ Hata ({img_path.name}): {e}")
        
        return sonuclar


def karsilastirma_testi():
    """Ä°ki yÃ¶ntemi karÅŸÄ±laÅŸtÄ±rmalÄ± test et"""
    print("\n" + "=" * 70)
    print("ğŸ”¬ HÄ°BRÄ°T SÄ°STEM KARÅILAÅTIRMALI TEST")
    print("=" * 70)
    
    # Test gÃ¶rÃ¼ntÃ¼sÃ¼
    test_img = './test_images/vida1.jpg'
    
    if not Path(test_img).exists():
        print(f"âš ï¸  Test gÃ¶rÃ¼ntÃ¼sÃ¼ bulunamadÄ±: {test_img}")
        print("\nÃ–nce test_images/ klasÃ¶rÃ¼ne Ã¶rnek gÃ¶rÃ¼ntÃ¼ler ekleyin!")
        return
    
    # 1. Sadece Feature Matching
    print("\n1ï¸âƒ£  FEATURE MATCHING ONLY")
    print("-" * 70)
    try:
        sistem1 = HibritTanima(
            referans_klasor='./referans_gorseller',
            mod='feature_only'
        )
        sonuc1 = sistem1.tanima_yap(test_img)
    except Exception as e:
        print(f"âŒ Feature Matching hatasÄ±: {e}")
        sonuc1 = None
    
    # 2. Sadece Deep Learning (varsa)
    print("\n2ï¸âƒ£  DEEP LEARNING ONLY")
    print("-" * 70)
    try:
        sistem2 = HibritTanima(
            model_path='best_model.pth',
            mod='dl_only'
        )
        sonuc2 = sistem2.tanima_yap(test_img)
    except Exception as e:
        print(f"âŒ Deep Learning hatasÄ±: {e}")
        sonuc2 = None
    
    # 3. Hibrit (Auto)
    print("\n3ï¸âƒ£  HYBRID (AUTO)")
    print("-" * 70)
    try:
        sistem3 = HibritTanima(
            model_path='best_model.pth',
            referans_klasor='./referans_gorseller',
            mod='auto',
            guven_esik=0.7
        )
        sonuc3 = sistem3.tanima_yap(test_img)
    except Exception as e:
        print(f"âŒ Hibrit hatasÄ±: {e}")
        sonuc3 = None
    
    # 4. Ensemble
    print("\n4ï¸âƒ£  ENSEMBLE")
    print("-" * 70)
    try:
        sistem4 = HibritTanima(
            model_path='best_model.pth',
            referans_klasor='./referans_gorseller',
            mod='ensemble'
        )
        sonuc4 = sistem4.tanima_yap(test_img)
    except Exception as e:
        print(f"âŒ Ensemble hatasÄ±: {e}")
        sonuc4 = None
    
    # KarÅŸÄ±laÅŸtÄ±rma
    print("\n" + "=" * 70)
    print("ğŸ“Š KARÅILAÅTIRMA SONUÃ‡LARI")
    print("=" * 70)
    
    sonuclar = [
        ("Feature Matching", sonuc1),
        ("Deep Learning", sonuc2),
        ("Hybrid Auto", sonuc3),
        ("Ensemble", sonuc4)
    ]
    
    for yontem, sonuc in sonuclar:
        if sonuc:
            print(f"\n{yontem}:")
            print(f"  ParÃ§a: {sonuc['parca']}")
            print(f"  GÃ¼ven: {sonuc['guven']:.3f}")
        else:
            print(f"\n{yontem}: KullanÄ±lamadÄ±")
    
    print("\n" + "=" * 70)


if __name__ == "__main__":
    karsilastirma_testi()
