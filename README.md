# Toplu DokÃ¼mantasyon
Bu README tÃ¼m .md iÃ§eriklerinin birleÅŸtirilmiÅŸ halidir.

## Ä°Ã§indekiler
- [1. GENEL BAKIS (Ã–nceki README)](#genel-bakis-Ã¶nceki-readme)
- [2. PROJE_OZETI.md](#projeozetimd)
- [3. QUICKSTART.md](#quickstartmd)
- [4. 15_DAKIKA_HIZLI_BASLANGIC.md](#15dakikahizlibaslangicmd)
- [5. TRAINING_DATA_REHBER.md](#trainingdatarehbermd)
- [6. VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md](#veritoplamayolharitasimd)
- [7. YONTEM_KARSILASTIRMA.md](#yontemkarsilastirmamd)
- [8. SEKIL_ANALIZI_GELISTIRME.md](#sekilanalizigelistirmemd)
- [9. EXAMPLES.md](#examplesmd)
- [10. HATA_COZUMU_VE_YOLHARITASI.md](#hatacozumuveyolharitasimd)
- [11. KLASOR_FARKLARI.md](#klasorfarklarimd)

## 1. GENEL BAKIS (Ã–nceki README)

# ğŸ”§ Makine ParÃ§asÄ± TanÄ±ma Sistemi

GÃ¶rÃ¼ntÃ¼ iÅŸleme ve yapay zeka teknolojileri kullanarak makine parÃ§alarÄ±nÄ± tanÄ±yan ve onlar hakkÄ±nda detaylÄ± bilgi veren **hibrit** Python tabanlÄ± sistemdir.

## ğŸ¯ Ã–zellikler

- **ğŸ¤– 3 FarklÄ± TanÄ±ma YÃ¶ntemi**: 
  - Feature Matching (HÄ±zlÄ± prototip)
  - Deep Learning (YÃ¼ksek doÄŸruluk)
  - Hibrit Sistem (En iyi sonuÃ§)
- **ğŸ”· AkÄ±llÄ± Åekil Analizi**: Dairesellik, kÃ¶ÅŸe sayÄ±sÄ± ve form analizi ile tahmin iyileÅŸtirme
- **ğŸ¨ GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme**: OpenCV ile geliÅŸmiÅŸ gÃ¶rÃ¼ntÃ¼ analizi
- **ğŸ§  AkÄ±llÄ± TanÄ±ma**: Otomatik yÃ¶ntem seÃ§imi ve ÅŸekil-parÃ§a eÅŸleÅŸtirme
- **ğŸ“Š DetaylÄ± Bilgi**: Her parÃ§a iÃ§in kapsamlÄ± bilgi sunumu
- **ğŸ–¥ï¸ Web ArayÃ¼zÃ¼**: Streamlit ile kullanÄ±cÄ± dostu arayÃ¼z
- **âš¡ GerÃ§ek ZamanlÄ± Analiz**: HÄ±zlÄ± ve etkili iÅŸleme
- **ğŸ”„ Esnek Mimari**: Kolay geniÅŸletilebilir ve Ã¶zelleÅŸtirilebilir

## ğŸ†• Yeni: Åekil Analizi ile AkÄ±llÄ± TanÄ±ma

Sistem artÄ±k **ÅŸekil analizi** yaparak daha doÄŸru tahminler Ã¼retiyor:

- ğŸ”´ **Daire/Elips tespit edildi** â†’ Rulman/Somun Ã¶ncelikli (+%30 bonus)
- ğŸ”µ **Uzun dikdÃ¶rtgen tespit edildi** â†’ Vida/Yay Ã¶ncelikli (+%25 bonus)
- ğŸŸ¢ **AltÄ±gen tespit edildi** â†’ DiÅŸli/Somun Ã¶ncelikli (+%25 bonus)

**SonuÃ§:** ~%30 daha yÃ¼ksek doÄŸruluk! ([DetaylÄ± bilgi](#sekilanalizigelistirmemd))

## ğŸ“‹ Desteklenen ParÃ§alar

- âœ… Vida
- âœ… Somun
- âœ… Rulman
- âœ… KayÄ±ÅŸ
- âœ… DiÅŸli
- âœ… Piston
- âœ… Supap (Valf)
- âœ… Krank Mili
- âœ… Yay
- âœ… Kaynak BaÄŸlantÄ±sÄ±

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Kurulum

```bash
# BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle
pip install -r requirements.txt

# KlasÃ¶r yapÄ±sÄ±nÄ± oluÅŸtur
chmod +x setup_folders.sh
./setup_folders.sh
```

### 2. Veri Toplama (Ã–NEMLÄ°!)

Sistem Ã§alÄ±ÅŸmak iÃ§in **eÄŸitim verisi** gerektirir. Ä°ki seÃ§eneÄŸiniz var:

#### ğŸ¯ HIZLI BAÅLANGIÃ‡ (15 dakika)
En hÄ±zlÄ± yÃ¶ntem - sadece 30 gÃ¶rÃ¼ntÃ¼ ile test edin:

```bash
# AdÄ±m adÄ±m rehber
./baslangic_rehberi.sh

# Veya manuel:
# 1. Google GÃ¶rseller'den her parÃ§a iÃ§in 10 gÃ¶rÃ¼ntÃ¼ indirin
# 2. training_data/[parca_adi]/ klasÃ¶rlerine koyun
# 3. Model eÄŸitin
```

ğŸ“– **DetaylÄ± rehber:** [15 Dakikada Ä°lk Model](#15dakikahizlibaslangicmd)

#### ğŸ“š KAPSAMLI YAKLAÅIM
Daha iyi sonuÃ§lar iÃ§in:

```bash
# Durum kontrolÃ¼
python check_training_data.py

# Her parÃ§a iÃ§in 50-100 gÃ¶rÃ¼ntÃ¼ ekleyin
# Rehber: TRAINING_DATA_REHBER.md
```

### 3. Model EÄŸitimi

```bash
# Ä°lk test eÄŸitimi (10-20 gÃ¶rÃ¼ntÃ¼/parÃ§a varsa)
python train_model.py --mode train --data_dir ./training_data --epochs 10

# Orta seviye eÄŸitim (50+ gÃ¶rÃ¼ntÃ¼/parÃ§a varsa)
python train_model.py --mode train --data_dir ./training_data --epochs 30

# Profesyonel eÄŸitim (100+ gÃ¶rÃ¼ntÃ¼/parÃ§a varsa)
python train_model.py --mode train --data_dir ./training_data --epochs 50
```

### 4. UygulamayÄ± Ã‡alÄ±ÅŸtÄ±r

```bash
streamlit run app.py
```

TarayÄ±cÄ±nÄ±zda otomatik olarak `http://localhost:8501` adresi aÃ§Ä±lacaktÄ±r.

### 3. Ä°lk TanÄ±mayÄ± Yap

1. Sol panelden **"Hibrit (Otomatik)"** yÃ¶ntemini seÃ§in
2. Bir makine parÃ§asÄ± gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
3. **"Analiz Et"** butonuna tÄ±klayÄ±n
4. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin!

ğŸ“– **DetaylÄ± kÄ±lavuz**: `QUICKSTART.md` dosyasÄ±na bakÄ±n

## ğŸ’» KullanÄ±m YÃ¶ntemleri

### ğŸŒ Web ArayÃ¼zÃ¼ (Ã–nerilen)

```bash
streamlit run app.py
```

**Ã–zellikler**:
- 5 farklÄ± tanÄ±ma yÃ¶ntemi seÃ§imi
- GerÃ§ek zamanlÄ± gÃ¶rÃ¼ntÃ¼ iÅŸleme
- DetaylÄ± sonuÃ§ analizi
- GÃ¼ven skorlarÄ± ve yÃ¶ntem karÅŸÄ±laÅŸtÄ±rmasÄ±

### ğŸ Python API

#### Feature Matching
```python
from feature_matcher import FeatureMatchingTanima

matcher = FeatureMatchingTanima('./referans_gorseller')
sonuclar = matcher.tanima_yap('test.jpg')
print(f"ParÃ§a: {sonuclar[0]['parca_adi']}")
```

#### Deep Learning
```bash
python train_model.py --mode test --test_image test.jpg
```

#### Hibrit Sistem
```python
from hybrid_detector import HibritTanima

sistem = HibritTanima(
    model_path='best_model.pth',
    referans_klasor='./referans_gorseller',
    mod='auto'
)
sonuc = sistem.tanima_yap('test.jpg')
```

ğŸ“– **Daha fazla Ã¶rnek**: `EXAMPLES.md` dosyasÄ±na bakÄ±n

## ğŸ”¬ Teknik Detaylar

### 3 TanÄ±ma YÃ¶ntemi KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Ã–zellik | Feature Matching | Deep Learning | Hibrit |
|---------|-----------------|---------------|---------|
| **DoÄŸruluk** | %60-75 | %85-98 | **%90-99** |
| **HÄ±z** | âš¡âš¡âš¡ 50ms | âš¡âš¡ 100ms | âš¡âš¡ 120ms |
| **Veri Ä°htiyacÄ±** | 5-10/sÄ±nÄ±f | 100+/sÄ±nÄ±f | 50+/sÄ±nÄ±f |
| **EÄŸitim** | Yok | 2-10 saat | 2-10 saat |
| **GPU** | âŒ | âœ… | âœ… (EÄŸitim iÃ§in) |
| **Yeni SÄ±nÄ±f** | âš¡ AnÄ±nda | ğŸŒ Yeniden eÄŸitim | ğŸš€ HÄ±zlÄ± |

ğŸ“– **DetaylÄ± karÅŸÄ±laÅŸtÄ±rma**: `YONTEM_KARSILASTIRMA.md`

### GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme Pipeline

```
GÃ¶rÃ¼ntÃ¼ â†’ Ã–n Ä°ÅŸleme â†’ Ã–zellik Ã‡Ä±karma â†’ TanÄ±ma â†’ SonuÃ§
           â†“              â†“                â†“
        - CLAHE      - SIFT/ORB       - DL Model
        - Denoising  - Histogram      - FM Matching
        - Canny      - Hu Moments     - Ensemble
```

### Hibrit Sistem Stratejisi

```python
def tanima_yap(image):
    # 1. Deep Learning dene
    dl_result = dl_model.predict(image)
    
    if dl_result.confidence > 0.85:
        return dl_result  # Yeterince gÃ¼venli
    
    # 2. Feature Matching ekle
    fm_result = feature_matcher.match(image)
    
    # 3. SonuÃ§larÄ± birleÅŸtir
    return ensemble(dl_result, fm_result)
```

## ğŸ¨ Ã–rnek KullanÄ±m SenaryolarÄ±

### 1. 3D Modelleme UygulamalarÄ±
Bir 3D CAD programÄ±nda tasarlanan parÃ§anÄ±n ne iÅŸe yaradÄ±ÄŸÄ±nÄ± anlamak

### 2. EÄŸitim ve Ã–ÄŸretim
Ã–ÄŸrencilere makine parÃ§alarÄ±nÄ± tanÄ±tmak

### 3. BakÄ±m ve OnarÄ±m
Tamir sÄ±rasÄ±nda bilinmeyen bir parÃ§ayÄ± tanÄ±mlamak

### 4. Envanter YÃ¶netimi
Stokta bulunan parÃ§alarÄ± kataloglamak

## âœ¨ Mevcut Ã–zellikler

- âœ… **3 TanÄ±ma YÃ¶ntemi**: Feature Matching, Deep Learning, Hibrit
- âœ… **Kendi Modelinizi EÄŸitin**: `train_model.py` ile
- âœ… **Web ArayÃ¼zÃ¼**: Streamlit ile kullanÄ±cÄ± dostu
- âœ… **KapsamlÄ± DokÃ¼mantasyon**: 5+ dÃ¶kÃ¼man dosyasÄ±
- âœ… **Esnek API**: Python, CLI, web arayÃ¼zÃ¼
- âœ… **GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme AraÃ§larÄ±**: `image_utils.py`
- âœ… **Referans VeritabanÄ±**: 10 parÃ§a tanÄ±mÄ±

## ğŸ”„ GeliÅŸmiÅŸ Ã–zellikler (Gelecek)

- [ ] Ã‡oklu parÃ§a tanÄ±ma (bir gÃ¶rÃ¼ntÃ¼de birden fazla parÃ§a)
- [ ] 3D model entegrasyonu
- [ ] ParÃ§a Ã¶lÃ§Ã¼m ve boyutlandÄ±rma
- [ ] Web tabanlÄ± eÄŸitim arayÃ¼zÃ¼
- [ ] REST API servisi
- [ ] Mobil uygulama (React Native)
- [ ] Real-time video tanÄ±ma
- [ ] Kalite kontrol modÃ¼lÃ¼

## ğŸ“Š Sistem Mimarisi

```
app.py
â”œâ”€â”€ MakineParcaTanima (Ana SÄ±nÄ±f)
â”‚   â”œâ”€â”€ goruntu_onisleme()      # GÃ¶rÃ¼ntÃ¼ Ã¶n iÅŸleme
â”‚   â”œâ”€â”€ ozellik_cikarma()       # Ã–zellik Ã§Ä±karma
â”‚   â”œâ”€â”€ parca_tanima_basit()    # ParÃ§a tanÄ±ma
â”‚   â””â”€â”€ bilgi_getir()           # Bilgi sorgulama
â”‚
â””â”€â”€ main()                       # Streamlit arayÃ¼zÃ¼
    â”œâ”€â”€ GÃ¶rÃ¼ntÃ¼ yÃ¼kleme
    â”œâ”€â”€ Analiz iÅŸlemi
    â””â”€â”€ SonuÃ§ gÃ¶sterimi
```

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/YeniOzellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/YeniOzellik`)
5. Pull Request oluÅŸturun

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici NotlarÄ±

### Model Ä°yileÅŸtirme

Daha iyi sonuÃ§lar iÃ§in:
- Daha fazla eÄŸitim verisi toplayÄ±n
- Transfer learning kullanÄ±n (ResNet, VGG, EfficientNet)
- Data augmentation uygulayÄ±n
- Ensemble yÃ¶ntemleri deneyin

### Performans Optimizasyonu

- GPU kullanÄ±mÄ±
- Batch processing
- GÃ¶rÃ¼ntÃ¼ Ã¶nbellekleme
- Asenkron iÅŸleme

## ğŸ› Bilinen Sorunlar

- BazÄ± karmaÅŸÄ±k parÃ§alar yanlÄ±ÅŸ tanÄ±mlanabilir
- DÃ¼ÅŸÃ¼k kaliteli gÃ¶rÃ¼ntÃ¼lerde performans dÃ¼ÅŸebilir
- Benzer parÃ§alar karÄ±ÅŸtÄ±rÄ±labilir

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in issue aÃ§abilirsiniz.

---

**Not**: Bu sistem ÅŸu anda kural tabanlÄ± tanÄ±ma kullanmaktadÄ±r. Daha hassas sonuÃ§lar iÃ§in makine Ã¶ÄŸrenmesi modeli eÄŸitilmesi Ã¶nerilir.

## 2. PROJE_OZETI.md

# ğŸ”§ Makine ParÃ§asÄ± TanÄ±ma Sistemi - Proje Ã–zeti

## ğŸ“¦ Proje YapÄ±sÄ±

```
makine_parca_tanima/
â”‚
â”œâ”€â”€ ğŸ“„ Ana Uygulama DosyalarÄ±
â”‚   â”œâ”€â”€ app.py                    # Streamlit web arayÃ¼zÃ¼ (GÃœNCEL - Hibrit destekli)
â”‚   â”œâ”€â”€ feature_matcher.py        # Feature matching sistemi (YENÄ°!)
â”‚   â”œâ”€â”€ hybrid_detector.py        # Hibrit tanÄ±ma sistemi (YENÄ°!)
â”‚   â”œâ”€â”€ train_model.py            # Deep learning eÄŸitim scripti
â”‚   â””â”€â”€ image_utils.py            # GÃ¶rÃ¼ntÃ¼ iÅŸleme araÃ§larÄ±
â”‚
â”œâ”€â”€ ğŸ“š DokÃ¼mantasyon
â”‚   â”œâ”€â”€ README.md                 # Genel bakÄ±ÅŸ ve kurulum
â”‚   â”œâ”€â”€ QUICKSTART.md             # HÄ±zlÄ± baÅŸlangÄ±Ã§ (YENÄ°!)
â”‚   â”œâ”€â”€ YONTEM_KARSILASTIRMA.md  # DetaylÄ± yÃ¶ntem analizi (YENÄ°!)
â”‚   â””â”€â”€ EXAMPLES.md               # KullanÄ±m Ã¶rnekleri
â”‚
â”œâ”€â”€ âš™ï¸ YapÄ±landÄ±rma
â”‚   â”œâ”€â”€ requirements.txt          # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â”œâ”€â”€ .gitignore               # Git ignore dosyasÄ±
â”‚   â””â”€â”€ setup_folders.sh         # KlasÃ¶r yapÄ±sÄ± kurulum (YENÄ°!)
â”‚
â””â”€â”€ ğŸ“ Veri KlasÃ¶rleri
    â”œâ”€â”€ referans_gorseller/      # Feature matching referanslarÄ± (YENÄ°!)
    â”‚   â”œâ”€â”€ vida/
    â”‚   â”œâ”€â”€ somun/
    â”‚   â””â”€â”€ ...
    â”œâ”€â”€ training_data/           # Deep learning eÄŸitim verisi (YENÄ°!)
    â”‚   â”œâ”€â”€ vida/
    â”‚   â””â”€â”€ ...
    â””â”€â”€ test_images/             # Test gÃ¶rÃ¼ntÃ¼leri (YENÄ°!)
```

## ğŸ¯ 3 FarklÄ± TanÄ±ma YÃ¶ntemi

### 1ï¸âƒ£ Feature Matching (GÃ¶rÃ¼ntÃ¼ Benzerlik)
**Dosya**: `feature_matcher.py`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r?**
- SIFT algoritmasÄ± ile Ã¶nemli noktalarÄ± (keypoints) bulur
- Renk histogramlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
- Hu moments ile ÅŸekil benzerliÄŸi hesaplar
- Referans gÃ¶rÃ¼ntÃ¼lerle eÅŸleÅŸtirir

**KullanÄ±m**:
```python
from feature_matcher import FeatureMatchingTanima

matcher = FeatureMatchingTanima('./referans_gorseller')
sonuclar = matcher.tanima_yap('test.jpg', method='hybrid')

print(f"ParÃ§a: {sonuclar[0]['parca_adi']}")
print(f"Skor: {sonuclar[0]['skor']}")
```

**AvantajlarÄ±**:
âœ… EÄŸitim gerektirmez
âœ… 5-10 gÃ¶rÃ¼ntÃ¼ ile Ã§alÄ±ÅŸÄ±r
âœ… HÄ±zlÄ± (50ms)
âœ… Kolay geniÅŸletilebilir

**DezavantajlarÄ±**:
âŒ DoÄŸruluk: %60-75
âŒ FarklÄ± aÃ§Ä±larda zayÄ±f

### 2ï¸âƒ£ Deep Learning (CNN)
**Dosya**: `train_model.py`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r?**
- ResNet50 transfer learning
- 100+ gÃ¶rÃ¼ntÃ¼ ile eÄŸitilir
- Neural network ile sÄ±nÄ±flandÄ±rÄ±r
- GÃ¼ven skoru verir

**KullanÄ±m**:
```bash
# EÄŸitim
python train_model.py --mode train --data_dir ./training_data

# Test
python train_model.py --mode test --test_image test.jpg
```

**AvantajlarÄ±**:
âœ… YÃ¼ksek doÄŸruluk (%85-98)
âœ… FarklÄ± aÃ§Ä±lara robust
âœ… Ã–lÃ§eklenebilir

**DezavantajlarÄ±**:
âŒ 100+ gÃ¶rÃ¼ntÃ¼ gerekir
âŒ EÄŸitim sÃ¼resi uzun
âŒ GPU gerekebilir

### 3ï¸âƒ£ Hibrit Sistem (En Ä°yi!) ğŸŒŸ
**Dosya**: `hybrid_detector.py`

**NasÄ±l Ã‡alÄ±ÅŸÄ±r?**
- Ä°ki yÃ¶ntemi akÄ±llÄ±ca birleÅŸtirir
- Otomatik mod: DL Ã¶nce, gÃ¼ven dÃ¼ÅŸÃ¼kse FM ekler
- Ensemble mod: Her ikisini birleÅŸtirir

**KullanÄ±m**:
```python
from hybrid_detector import HibritTanima

sistem = HibritTanima(
    model_path='best_model.pth',
    referans_klasor='./referans_gorseller',
    mod='auto'  # veya 'ensemble'
)

sonuc = sistem.tanima_yap('test.jpg')
```

**Modlar**:
- `auto`: AkÄ±llÄ± seÃ§im (Ã¶nerilen)
- `ensemble`: Her ikisini birleÅŸtir
- `dl_only`: Sadece deep learning
- `feature_only`: Sadece feature matching

## ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§

### 1. Sistemleri Dene (5 dakika)

```bash
# Web arayÃ¼zÃ¼nÃ¼ baÅŸlat
streamlit run app.py
```

TarayÄ±cÄ±da:
- Sol panelden yÃ¶ntem seÃ§: **"Hibrit (Otomatik)"**
- GÃ¶rÃ¼ntÃ¼ yÃ¼kle
- Analiz et

### 2. Referans GÃ¶rÃ¼ntÃ¼ler Ekle (30 dakika)

```bash
# Her parÃ§a iÃ§in 5-10 gÃ¶rÃ¼ntÃ¼ ekleyin
referans_gorseller/
â”œâ”€â”€ vida/
â”‚   â”œâ”€â”€ vida1.jpg
â”‚   â”œâ”€â”€ vida2.jpg
â”‚   â””â”€â”€ vida3.jpg
â””â”€â”€ ...
```

Google'dan indir veya telefon ile Ã§ek!

### 3. Test Et

```python
python feature_matcher.py  # Feature matching test
python hybrid_detector.py  # KarÅŸÄ±laÅŸtÄ±rmalÄ± test
```

### 4. Ä°steÄŸe BaÄŸlÄ±: Model EÄŸit (GeliÅŸmiÅŸ)

```bash
# Ã–nce veri topla (100+ gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f)
# Sonra eÄŸit:
python train_model.py --mode train --data_dir ./training_data --epochs 25
```

## ğŸ“Š Hangi YÃ¶ntemi KullanmalÄ±yÄ±m?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Az Veri (<20/sÄ±nÄ±f)                       â”‚
â”‚  â†’ Feature Matching                         â”‚
â”‚  â†’ HÄ±zlÄ± prototip                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Orta Veri (20-100/sÄ±nÄ±f)                  â”‚
â”‚  â†’ Hibrit Auto Mod                          â”‚
â”‚  â†’ Ä°yi denge                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ã‡ok Veri (100+/sÄ±nÄ±f)                     â”‚
â”‚  â†’ Deep Learning veya Ensemble              â”‚
â”‚  â†’ En yÃ¼ksek doÄŸruluk                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸª GerÃ§ek KullanÄ±m SenaryolarÄ±

### Senaryo 1: 3D CAD YazÄ±lÄ±mÄ± Entegrasyonu
```python
# CAD yazÄ±lÄ±mÄ±ndan screenshot al
screenshot = get_viewport_screenshot()

# TanÄ±
from hybrid_detector import HibritTanima
sistem = HibritTanima(mod='auto')
sonuc = sistem.tanima_yap(screenshot)

# Bilgi panelini gÃ¶ster
show_part_info(
    name=sonuc['parca'],
    confidence=sonuc['guven'],
    method=sonuc['method']
)
```

### Senaryo 2: Mobil AR UygulamasÄ±
```python
# Kamera gÃ¶rÃ¼ntÃ¼sÃ¼
camera_frame = capture_frame()

# Optimized model (mobil iÃ§in)
sistem = HibritTanima(
    model_path='mobile_optimized.pth',
    mod='dl_only'
)

# HÄ±zlÄ± tanÄ±ma
sonuc = sistem.tanima_yap(camera_frame)

# AR overlay gÃ¶ster
display_ar_overlay(sonuc['parca'])
```

### Senaryo 3: EndÃ¼striyel Kalite Kontrol
```python
# KonveyÃ¶r bandÄ±ndan gÃ¶rÃ¼ntÃ¼
conveyor_image = get_conveyor_image()

# YÃ¼ksek doÄŸruluk iÃ§in ensemble
sistem = HibritTanima(mod='ensemble')
sonuc = sistem.tanima_yap(conveyor_image)

# Otomatik sÄ±nÄ±flandÄ±rma
if sonuc['guven'] > 0.95:
    auto_sort(sonuc['parca'])
else:
    request_manual_inspection()
```

## ğŸ”¬ Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | Feature | DL | Hibrit |
|--------|---------|-----|---------|
| DoÄŸruluk | 60-75% | 85-98% | **90-99%** |
| HÄ±z | âš¡âš¡âš¡ | âš¡âš¡ | âš¡âš¡ |
| Veri | 5-10 | 100+ | 50+ |
| EÄŸitim | Yok | 2-10h | 2-10h |
| GPU | âŒ | âœ… | âœ… |
| GeniÅŸletme | âš¡ | ğŸŒ | ğŸš€ |

## ğŸ’¡ Ã–nemli Ä°puÃ§larÄ±

### Veri Toplama
1. **Kaliteli gÃ¶rÃ¼ntÃ¼ler**: 800x600 minimum Ã§Ã¶zÃ¼nÃ¼rlÃ¼k
2. **FarklÄ± aÃ§Ä±lar**: Her parÃ§a iÃ§in 3-5 farklÄ± aÃ§Ä±dan
3. **Temiz arka plan**: Beyaz/gri ideal
4. **Ä°yi aydÄ±nlatma**: DoÄŸal veya LED Ä±ÅŸÄ±k

### Model EÄŸitimi
1. **Transfer learning**: ResNet50 ile baÅŸla
2. **Data augmentation**: Veriyi 5-10x artÄ±r
3. **Early stopping**: Overfitting'i Ã¶nle
4. **Validation**: %20 veriyi test iÃ§in ayÄ±r

### Production Deployment
1. **Model optimizasyonu**: Quantization kullan
2. **Caching**: SÄ±k kullanÄ±lan sonuÃ§larÄ± cache'le
3. **Monitoring**: DoÄŸruluk oranlarÄ±nÄ± takip et
4. **Feedback loop**: KullanÄ±cÄ± dÃ¼zeltmelerini topla

## ğŸ“ Sorun mu YaÅŸÄ±yorsunuz?

### "DÃ¼ÅŸÃ¼k doÄŸruluk alÄ±yorum"
1. Daha fazla referans gÃ¶rÃ¼ntÃ¼ ekleyin
2. GÃ¶rÃ¼ntÃ¼ kalitesini artÄ±rÄ±n
3. Arka planÄ± temizleyin
4. Hibrit mod kullanÄ±n

### "Sistem yavaÅŸ Ã§alÄ±ÅŸÄ±yor"
1. GPU kullanÄ±n (eÄŸitim iÃ§in)
2. Model'i quantize edin
3. GÃ¶rÃ¼ntÃ¼ boyutunu optimize edin
4. Batch processing kullanÄ±n

### "Yeni parÃ§a eklemek istiyorum"
**Feature Matching**: Sadece referans gÃ¶rÃ¼ntÃ¼ ekleyin! âš¡
**Deep Learning**: Yeniden eÄŸitim gerekli ğŸŒ
**Hibrit**: Feature matching'e ekleyin, zaman buldukÃ§a model eÄŸitin ğŸš€

## ğŸ¯ Sonraki AdÄ±mlar

1. âœ… **Åimdi**: Feature matching ile baÅŸla
2. ğŸ“¸ **Bu hafta**: Referans gÃ¶rÃ¼ntÃ¼ler topla
3. ğŸ“ **Bu ay**: Model eÄŸitimi iÃ§in veri topla
4. ğŸš€ **Gelecek ay**: Hibrit sistem ile production'a al
5. ğŸ“ˆ **SÃ¼rekli**: KullanÄ±cÄ± feedback ile iyileÅŸtir

## ğŸ“š Daha Fazla Bilgi

- **Teori**: `YONTEM_KARSILASTIRMA.md`
- **HÄ±zlÄ± baÅŸlangÄ±Ã§**: `QUICKSTART.md`
- **Kod Ã¶rnekleri**: `EXAMPLES.md`
- **Genel bilgi**: `README.md`

---

## ğŸ‰ Ã–zet

Size **3 farklÄ± yaklaÅŸÄ±mlÄ±**, **esnek** ve **Ã¶lÃ§eklenebilir** bir makine parÃ§asÄ± tanÄ±ma sistemi oluÅŸturduk:

1. **Feature Matching**: HÄ±zlÄ± prototip iÃ§in
2. **Deep Learning**: YÃ¼ksek doÄŸruluk iÃ§in
3. **Hibrit**: Her ikisinin en iyisi iÃ§in

**Ã–nerimiz**: Hibrit Auto mod ile baÅŸlayÄ±n, veri topladÄ±kÃ§a model eÄŸitin, production'da ensemble kullanÄ±n!

**BaÅŸarÄ±lar! ğŸš€**

## 3. QUICKSTART.md

# ğŸš€ HÄ±zlÄ± BaÅŸlangÄ±Ã§ KÄ±lavuzu

Sisteminizi 3 adÄ±mda Ã§alÄ±ÅŸtÄ±rÄ±n!

## AdÄ±m 1: KlasÃ¶rleri OluÅŸtur

```bash
chmod +x setup_folders.sh
./setup_folders.sh
```

veya manuel:
```bash
mkdir -p referans_gorseller/{vida,somun,rulman,kayis,disli,piston}
mkdir -p test_images
mkdir -p training_data/{vida,somun,rulman}
```

## AdÄ±m 2: Referans GÃ¶rÃ¼ntÃ¼ler Ekle

Her parÃ§a iÃ§in **5-10 Ã¶rnek gÃ¶rÃ¼ntÃ¼** ekleyin:

```
referans_gorseller/
â”œâ”€â”€ vida/
â”‚   â”œâ”€â”€ vida1.jpg
â”‚   â”œâ”€â”€ vida2.jpg
â”‚   â””â”€â”€ vida3.jpg
â”œâ”€â”€ somun/
â”‚   â”œâ”€â”€ somun1.jpg
â”‚   â””â”€â”€ somun2.jpg
â””â”€â”€ ...
```

ğŸ’¡ **Nereden bulabilirsiniz?**
- Google GÃ¶rseller
- Telefon kameranÄ±z ile Ã§ekin
- Online parÃ§a kataloglarÄ±
- 3D modelleme yazÄ±lÄ±mÄ±ndan screenshot

## AdÄ±m 3: Sistemi KullanÄ±n

### A) Web ArayÃ¼zÃ¼ (En Kolay)

```bash
streamlit run app.py
```

TarayÄ±cÄ±da aÃ§Ä±lan arayÃ¼zde:
1. GÃ¶rÃ¼ntÃ¼ yÃ¼kleyin
2. YÃ¶ntemi seÃ§in: **"Hibrit (Otomatik)"**
3. Analiz Et'e tÄ±klayÄ±n

### B) Komut SatÄ±rÄ± (Feature Matching)

```python
from feature_matcher import FeatureMatchingTanima

# Sistem baÅŸlat
matcher = FeatureMatchingTanima('./referans_gorseller')

# Test et
sonuclar = matcher.tanima_yap('./test_images/test_vida.jpg')

# SonuÃ§larÄ± gÃ¶ster
for i, sonuc in enumerate(sonuclar[:3], 1):
    print(f"{i}. {sonuc['parca_adi']} - Skor: {sonuc['skor']:.3f}")
```

### C) Hibrit Sistem (En Ä°yi SonuÃ§)

```python
from hybrid_detector import HibritTanima

# Sistem baÅŸlat
sistem = HibritTanima(
    referans_klasor='./referans_gorseller',
    mod='auto'
)

# Test et
sonuc = sistem.tanima_yap('./test_images/test_vida.jpg')

print(f"ParÃ§a: {sonuc['parca']}")
print(f"GÃ¼ven: {sonuc['guven']:.2%}")
print(f"YÃ¶ntem: {sonuc['method']}")
```

## Ä°leri Seviye: Model EÄŸitimi

Daha yÃ¼ksek doÄŸruluk iÃ§in kendi modelinizi eÄŸitin:

### 1. Veri Toplama

Her parÃ§a iÃ§in **100+ gÃ¶rÃ¼ntÃ¼** toplayÄ±n:

```
training_data/
â”œâ”€â”€ vida/
â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â”œâ”€â”€ img_002.jpg
â”‚   â”œâ”€â”€ ... (100+ gÃ¶rÃ¼ntÃ¼)
â”œâ”€â”€ somun/
â”‚   â”œâ”€â”€ img_001.jpg
â”‚   â””â”€â”€ ... (100+ gÃ¶rÃ¼ntÃ¼)
```

### 2. Model EÄŸitimi

```bash
python train_model.py \
    --mode train \
    --data_dir ./training_data \
    --epochs 25 \
    --batch_size 32 \
    --lr 0.001
```

EÄŸitim tamamlandÄ±ÄŸÄ±nda `best_model.pth` dosyasÄ± oluÅŸacak.

### 3. Model Test

```bash
python train_model.py \
    --mode test \
    --model_path best_model.pth \
    --test_image ./test_images/vida1.jpg
```

### 4. Hibrit Sistemde Kullan

Model eÄŸitildikten sonra hibrit sistem otomatik olarak kullanacak:

```python
sistem = HibritTanima(
    model_path='best_model.pth',           # âœ… DL model
    referans_klasor='./referans_gorseller', # âœ… Feature matching
    mod='auto'                              # âœ… AkÄ±llÄ± mod
)
```

## ğŸ¯ Hangi YÃ¶ntemi KullanmalÄ±yÄ±m?

| Durum | Ã–nerilen YÃ¶ntem | Komut |
|-------|----------------|-------|
| HÄ±zlÄ± prototip | Feature Matching | `mod='feature_only'` |
| Az veri var (< 50/sÄ±nÄ±f) | Feature Matching | `mod='feature_only'` |
| Ã‡ok veri var (100+/sÄ±nÄ±f) | Deep Learning | `mod='dl_only'` |
| Production ortam | Hibrit Auto | `mod='auto'` |
| Kritik uygulama | Ensemble | `mod='ensemble'` |

## ğŸ“Š Performans Beklentileri

### Feature Matching
- âš¡ HÄ±z: ~50ms
- ğŸ“Š DoÄŸruluk: %60-75
- ğŸ’¾ Veri: 5-10/sÄ±nÄ±f
- ğŸ“ EÄŸitim: Yok

### Deep Learning
- âš¡ HÄ±z: ~100ms
- ğŸ“Š DoÄŸruluk: %85-98
- ğŸ’¾ Veri: 100+/sÄ±nÄ±f
- ğŸ“ EÄŸitim: 2-10 saat

### Hibrit (Auto)
- âš¡ HÄ±z: ~120ms
- ğŸ“Š DoÄŸruluk: %90-99
- ğŸ’¾ Veri: 50+/sÄ±nÄ±f
- ğŸ“ EÄŸitim: 2-10 saat

## ğŸ”§ Sorun Giderme

### "Referans veritabanÄ± boÅŸ"
```bash
# Referans gÃ¶rÃ¼ntÃ¼ler eklediniz mi?
ls -la referans_gorseller/vida/

# En az 1 gÃ¶rÃ¼ntÃ¼ olmalÄ±!
```

### "DL model yÃ¼klenemedi"
```bash
# Model eÄŸittiniz mi?
ls -la best_model.pth

# EÄŸitmediyseniz feature_only modunu kullanÄ±n
```

### "DÃ¼ÅŸÃ¼k doÄŸruluk"
1. Daha fazla referans gÃ¶rÃ¼ntÃ¼ ekleyin
2. FarklÄ± aÃ§Ä±lardan Ã§ekin
3. Ä°yi aydÄ±nlatma kullanÄ±n
4. Arka planÄ± temiz tutun

## ğŸ’¡ Ä°puÃ§larÄ±

1. **Kaliteli GÃ¶rÃ¼ntÃ¼ler**: Net, iyi aydÄ±nlatÄ±lmÄ±ÅŸ gÃ¶rÃ¼ntÃ¼ler kullanÄ±n
2. **FarklÄ± AÃ§Ä±lar**: Her parÃ§a iÃ§in farklÄ± aÃ§Ä±lardan Ã§ekin
3. **Temiz Arka Plan**: MÃ¼mkÃ¼nse beyaz/gri arka plan kullanÄ±n
4. **TutarlÄ± Boyut**: Benzer boyutlarda gÃ¶rÃ¼ntÃ¼ler daha iyi sonuÃ§ verir
5. **Veri Augmentation**: Az veriniz varsa augmentation kullanÄ±n

## ğŸ“ YardÄ±m

Sorun yaÅŸarsanÄ±z:
1. `YONTEM_KARSILASTIRMA.md` dosyasÄ±nÄ± okuyun
2. `EXAMPLES.md` dosyasÄ±ndaki Ã¶rneklere bakÄ±n
3. Hata mesajlarÄ±nÄ± dikkatlice okuyun
4. GitHub Issues'da sorun aÃ§Ä±n

---

**BaÅŸarÄ±lar! ğŸ‰**

## 4. 15_DAKIKA_HIZLI_BASLANGIC.md

# âš¡ HIZLI BAÅLANGIÃ‡ - 15 Dakikada Ä°lk Model

## ğŸ¯ Hedef
15-20 dakikada ilk 30 gÃ¶rÃ¼ntÃ¼ ile sistemi Ã§alÄ±ÅŸtÄ±rabilir hale getirin.

---

## ğŸ“ AdÄ±m AdÄ±m (3 ParÃ§a x 10 GÃ¶rÃ¼ntÃ¼ = 30 Toplam)

### 1ï¸âƒ£ VIDA (5 dakika)

**Google'da ara:**
```
hex bolt
```

**YapÄ±lacaklar:**
1. Google GÃ¶rseller'e girin
2. "hex bolt" yazÄ±n ve ara
3. 10 gÃ¶rÃ¼ntÃ¼ye saÄŸ tÄ±k â†’ "Resmi farklÄ± kaydet"
4. KayÄ±t yeri: `training_data/vida/`
5. Ä°simler: `vida_01.jpg`, `vida_02.jpg`, ... `vida_10.jpg`

âœ… **10 vida gÃ¶rÃ¼ntÃ¼sÃ¼ indirildi!**

---

### 2ï¸âƒ£ SOMUN (5 dakika)

**Google'da ara:**
```
hex nut
```

**YapÄ±lacaklar:**
1. "hex nut" ara
2. 10 gÃ¶rÃ¼ntÃ¼ indir
3. KayÄ±t yeri: `training_data/somun/`
4. Ä°simler: `somun_01.jpg`, `somun_02.jpg`, ... `somun_10.jpg`

âœ… **10 somun gÃ¶rÃ¼ntÃ¼sÃ¼ indirildi!**

---

### 3ï¸âƒ£ RULMAN (5 dakika)

**Google'da ara:**
```
ball bearing
```

**YapÄ±lacaklar:**
1. "ball bearing" ara
2. 10 gÃ¶rÃ¼ntÃ¼ indir
3. KayÄ±t yeri: `training_data/rulman/`
4. Ä°simler: `rulman_01.jpg`, `rulman_02.jpg`, ... `rulman_10.jpg`

âœ… **10 rulman gÃ¶rÃ¼ntÃ¼sÃ¼ indirildi!**

---

## âœ… Kontrol Edin

```bash
python check_training_data.py
```

**Beklenen Ã§Ä±ktÄ±:**
```
vida:    10 gÃ¶rÃ¼ntÃ¼  âœ…
somun:   10 gÃ¶rÃ¼ntÃ¼  âœ…
rulman:  10 gÃ¶rÃ¼ntÃ¼  âœ…
TOPLAM:  30 gÃ¶rÃ¼ntÃ¼
```

---

## ğŸš€ Ä°lk EÄŸitimi YapÄ±n

```bash
python train_model.py --mode train --data_dir ./training_data --epochs 10
```

**SÃ¼re:** ~2-5 dakika (CPU'da)

**SonuÃ§:** `best_model.pth` dosyasÄ± oluÅŸacak

---

## ğŸ‰ Test Edin

```bash
streamlit run app.py
```

1. TarayÄ±cÄ±da `http://localhost:8501` aÃ§Ä±lacak
2. Bir vida/somun/rulman gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
3. "Deep Learning" yÃ¶ntemini seÃ§in
4. "ğŸ” Analiz Et" butonuna basÄ±n

**SonuÃ§:** Sistem artÄ±k 3 parÃ§ayÄ± tanÄ±yabilir! ğŸŠ

---

## ğŸ“ˆ Sonraki AdÄ±mlar

### AynÄ± GÃ¼n (30 dakika)
- [ ] 3 parÃ§a daha ekleyin (diÅŸli, kayÄ±ÅŸ, piston)
- [ ] Her biri iÃ§in 10 gÃ¶rÃ¼ntÃ¼
- [ ] Toplam: 60 gÃ¶rÃ¼ntÃ¼
- [ ] Yeniden eÄŸitin (20 epoch)

### Bu Hafta
- [ ] 10 parÃ§anÄ±n tamamÄ±nÄ± ekleyin
- [ ] Her parÃ§a iÃ§in 20-30 gÃ¶rÃ¼ntÃ¼
- [ ] Toplam: 200-300 gÃ¶rÃ¼ntÃ¼
- [ ] 30 epoch eÄŸitim

### Bu Ay
- [ ] Her parÃ§a iÃ§in 100+ gÃ¶rÃ¼ntÃ¼
- [ ] Veri artÄ±rma uygulayÄ±n
- [ ] 50 epoch profesyonel eÄŸitim
- [ ] %90+ doÄŸruluk

---

## ğŸ” Ä°yi GÃ¶rÃ¼ntÃ¼ SeÃ§me Ä°puÃ§larÄ±

### âœ… Ä°yi
- Tek renkli arka plan (beyaz/gri)
- Net ve keskin
- ParÃ§a gÃ¶rÃ¼nÃ¼r
- 500x500 px veya daha bÃ¼yÃ¼k

### âŒ KÃ¶tÃ¼
- KarÄ±ÅŸÄ±k arka plan
- BulanÄ±k
- Ã‡ok kÃ¼Ã§Ã¼k
- Watermark/logo var

---

## ğŸ’¡ HÄ±zlÄ± PÃ¼f Noktalar

1. **Toplu indirme:**
   - Google GÃ¶rseller'de bir sekme aÃ§Ä±n
   - 10 gÃ¶rÃ¼ntÃ¼yÃ¼ bulun
   - Hepsine aynÄ± anda saÄŸ tÄ±k â†’ Ä°ndir
   - Toplu seÃ§ â†’ training_data/[klasÃ¶r]/ taÅŸÄ±

2. **Dosya isimlendirme:**
   - Otomatik: TarayÄ±cÄ± `vida (1).jpg`, `vida (2).jpg` diye kaydeder
   - Manuel rename gerekmez, sistem tÃ¼m .jpg dosyalarÄ±nÄ± okur

3. **HÄ±zlÄ± test:**
   - Ä°lk 30 gÃ¶rÃ¼ntÃ¼ ile test edin
   - Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼nce daha fazla ekleyin
   - YavaÅŸ yavaÅŸ ilerleyin

---

## ğŸ†˜ Sorun Giderme

### Sorun: "No such file or directory"
**Ã‡Ã¶zÃ¼m:**
```bash
# KlasÃ¶rleri kontrol edin
ls training_data/vida/
# BoÅŸsa, gÃ¶rÃ¼ntÃ¼leri doÄŸru klasÃ¶re koymadÄ±nÄ±z
```

### Sorun: "Insufficient data"
**Ã‡Ã¶zÃ¼m:**
```bash
# En az 10 gÃ¶rÃ¼ntÃ¼ gerekli
python check_training_data.py
# Eksik parÃ§alara gÃ¶rÃ¼ntÃ¼ ekleyin
```

### Sorun: EÄŸitim Ã§ok yavaÅŸ
**Ã‡Ã¶zÃ¼m:**
```bash
# GPU yoksa epoch sayÄ±sÄ±nÄ± azaltÄ±n
python train_model.py --mode train --data_dir ./training_data --epochs 5
```

---

## ğŸ¯ 15 Dakika Ã–zet

```
1. Google GÃ¶rseller â†’ "hex bolt"     â†’ 10 gÃ¶rÃ¼ntÃ¼ indir â†’ training_data/vida/     (5 dk)
2. Google GÃ¶rseller â†’ "hex nut"      â†’ 10 gÃ¶rÃ¼ntÃ¼ indir â†’ training_data/somun/    (5 dk)
3. Google GÃ¶rseller â†’ "ball bearing" â†’ 10 gÃ¶rÃ¼ntÃ¼ indir â†’ training_data/rulman/   (5 dk)
4. python check_training_data.py                                                  (10 sn)
5. python train_model.py --mode train --data_dir ./training_data --epochs 10      (3 dk)
6. streamlit run app.py                                                           (10 sn)
7. Test edin! ğŸ‰
```

**Toplam:** ~15-20 dakika

---

**ğŸš€ BaÅŸarÄ±lar! Sisteminiz artÄ±k Ã§alÄ±ÅŸÄ±yor!**

## 5. TRAINING_DATA_REHBER.md

# ğŸ“š Training Data KlasÃ¶rÃ¼ KullanÄ±m Rehberi

## ğŸ¯ Ne YapmalÄ±sÄ±nÄ±z?

`training_data/` klasÃ¶rÃ¼ne **her parÃ§a tÃ¼rÃ¼ iÃ§in en az 100-200 gÃ¶rÃ¼ntÃ¼** eklemelisiniz. Bu gÃ¶rÃ¼ntÃ¼ler Deep Learning modelini eÄŸitmek iÃ§in kullanÄ±lacak.

---

## ğŸ“ KlasÃ¶r YapÄ±sÄ±

```
training_data/
â”œâ”€â”€ vida/          â† Vida gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ somun/         â† Somun gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ rulman/        â† Rulman gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ kayis/         â† KayÄ±ÅŸ gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ disli/         â† DiÅŸli gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ piston/        â† Piston gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ supap/         â† Supap gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ krank/         â† Krank mili gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â”œâ”€â”€ yay/           â† Yay gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
â””â”€â”€ kaynak/        â† Kaynak gÃ¶rÃ¼ntÃ¼leri buraya (100-200 adet)
```

---

## ğŸ†š Ä°ki KlasÃ¶r ArasÄ±ndaki Fark

### 1ï¸âƒ£ `referans_gorseller/` (Feature Matching iÃ§in)
- **AmaÃ§:** HÄ±zlÄ± benzerlik karÅŸÄ±laÅŸtÄ±rmasÄ±
- **Gerekli miktar:** Her parÃ§a iÃ§in **5-10 gÃ¶rÃ¼ntÃ¼** yeterli
- **KullanÄ±m:** SIFT, Histogram, Hu Moments ile eÅŸleÅŸtirme
- **DoÄŸruluk:** ~%60-75

### 2ï¸âƒ£ `training_data/` (Deep Learning iÃ§in)
- **AmaÃ§:** Neural network eÄŸitimi
- **Gerekli miktar:** Her parÃ§a iÃ§in **100-200+ gÃ¶rÃ¼ntÃ¼**
- **KullanÄ±m:** ResNet50 modelini eÄŸitme
- **DoÄŸruluk:** ~%85-95

---

## ğŸš€ HIZLI BAÅLANGIÃ‡ (Ä°lk 1 Saat)

### SeÃ§enek 1: Manuel Ä°ndirme (Ã–NERÄ°LEN)

1. **Google GÃ¶rseller'den indirin:**
   ```
   1. Google'da arayÄ±n: "M8 vida", "hex bolt", "screw"
   2. GÃ¶rseller sekmesine gidin
   3. SaÄŸ tÄ±k â†’ "Resmi farklÄ± kaydet"
   4. training_data/vida/ klasÃ¶rÃ¼ne kaydedin
   5. Her parÃ§a iÃ§in tekrarlayÄ±n (Ã¶nce 10'ar tane ile baÅŸlayÄ±n)
   ```

2. **Unsplash.com'dan yÃ¼ksek kaliteli gÃ¶rseller:**
   ```
   - unsplash.com â†’ Arama: "bolt", "bearing", "gear"
   - Ãœcretsiz, yÃ¼ksek Ã§Ã¶zÃ¼nÃ¼rlÃ¼klÃ¼
   - Ä°ndir â†’ training_data/ilgili_klasor/
   ```

3. **Telefon kameranÄ±zla Ã§ekin:**
   ```
   ğŸ“¸ Ä°puÃ§larÄ±:
   - Beyaz/gri arka plan kullanÄ±n
   - Ä°yi Ä±ÅŸÄ±k altÄ±nda Ã§ekin
   - FarklÄ± aÃ§Ä±lardan (yukarÄ±, yan, 45Â°)
   - Her parÃ§adan 5-10 fotoÄŸraf
   ```

### SeÃ§enek 2: Otomatik Ä°ndirme Scripti

```bash
# HazÄ±r scripti kullanÄ±n
python download_images.py
```

Bu script size arama terimleri Ã¶nerecek ve manuel indirme talimatlarÄ± verecek.

---

## ğŸ“Š AÅAMALI YAKLAÅIM

### ğŸ¥‰ Minimum BaÅŸlangÄ±Ã§ (1-2 saat)
**Hedef:** Sistemi test etmek
```
Her parÃ§a iÃ§in: 10-20 gÃ¶rÃ¼ntÃ¼
Toplam: ~100-200 gÃ¶rÃ¼ntÃ¼
Beklenen doÄŸruluk: %70-80
```

**NasÄ±l:**
1. Her parÃ§a iÃ§in Google'dan 10 gÃ¶rÃ¼ntÃ¼ indirin
2. `training_data/` klasÃ¶rlerine atÄ±n
3. Model eÄŸitimi yapÄ±n:
   ```bash
   python train_model.py --mode train --data_dir ./training_data --epochs 10
   ```

### ğŸ¥ˆ Orta Seviye (1 hafta)
**Hedef:** KullanÄ±labilir sistem
```
Her parÃ§a iÃ§in: 50-100 gÃ¶rÃ¼ntÃ¼
Toplam: ~500-1000 gÃ¶rÃ¼ntÃ¼
Beklenen doÄŸruluk: %80-85
```

**NasÄ±l:**
1. Web'den 30-50 gÃ¶rÃ¼ntÃ¼ toplayÄ±n
2. Kendiniz 10-20 fotoÄŸraf Ã§ekin
3. Veri artÄ±rma (augmentation) uygulayÄ±n
4. Model eÄŸitimi:
   ```bash
   python train_model.py --mode train --data_dir ./training_data --epochs 30
   ```

### ğŸ¥‡ Profesyonel Seviye (1 ay)
**Hedef:** Ãœretim kalitesi sistem
```
Her parÃ§a iÃ§in: 200-500 gÃ¶rÃ¼ntÃ¼
Toplam: 2000-5000 gÃ¶rÃ¼ntÃ¼
Beklenen doÄŸruluk: %90-95+
```

**NasÄ±l:**
1. Ã‡eÅŸitli kaynaklardan veri toplayÄ±n
2. FarklÄ± arka planlar, aydÄ±nlatmalar
3. FarklÄ± aÃ§Ä±lar ve uzaklÄ±klar
4. Veri artÄ±rma ile 5-10x Ã§oÄŸaltÄ±n
5. Model eÄŸitimi:
   ```bash
   python train_model.py --mode train --data_dir ./training_data --epochs 50 --batch_size 32
   ```

---

## ğŸ–¼ï¸ GÃ¶rÃ¼ntÃ¼ Gereksinimleri

### âœ… Ä°DEAL GÃ¶rÃ¼ntÃ¼ Ã–zellikleri

```
âœ“ Format: JPG, JPEG, PNG
âœ“ Boyut: 500x500 - 2000x2000 piksel
âœ“ Dosya boyutu: 100KB - 5MB
âœ“ Arka plan: Tek renkli (beyaz/gri) veya dÃ¼z
âœ“ AydÄ±nlatma: Ä°yi, gÃ¶lgesiz
âœ“ Netlik: Keskin, bulanÄ±k deÄŸil
âœ“ Ã‡eÅŸitlilik: FarklÄ± aÃ§Ä±lar, uzaklÄ±klar, parÃ§a tipleri
```

### âŒ KaÃ§Ä±nÄ±lmasÄ± Gerekenler

```
âœ— Ã‡ok kÃ¼Ã§Ã¼k gÃ¶rÃ¼ntÃ¼ler (<200x200 px)
âœ— KarmaÅŸÄ±k arka planlar
âœ— BulanÄ±k/bozuk gÃ¶rÃ¼ntÃ¼ler
âœ— Ã‡ok fazla gÃ¶lge
âœ— AÅŸÄ±rÄ± yakÄ±n/uzak Ã§ekimler
âœ— Watermark/logo iÃ§eren gÃ¶rseller
âœ— AynÄ± gÃ¶rÃ¼ntÃ¼nÃ¼n kopyalarÄ±
```

---

## ğŸ” GÃ¶rÃ¼ntÃ¼ Bulma KaynaklarÄ±

### 1. Ãœcretsiz Stok FotoÄŸraf Siteleri
```
ğŸŒ Unsplash.com       - YÃ¼ksek kaliteli, Ã¼cretsiz
ğŸŒ Pexels.com         - GeniÅŸ koleksiyon
ğŸŒ Pixabay.com        - Ã‡eÅŸitli iÃ§erik
ğŸŒ Freepik.com        - BazÄ± Ã¼cretsiz gÃ¶rseller
```

### 2. Teknik/EndÃ¼striyel Kaynaklar
```
ğŸ”§ McMaster-Carr      - Teknik parÃ§a fotoÄŸraflarÄ±
ğŸ”§ Grainger.com       - EndÃ¼striyel katalog
ğŸ”§ RS Components      - Elektronik parÃ§alar
ğŸ”§ Alibaba            - ÃœrÃ¼n gÃ¶rÃ¼ntÃ¼leri
```

### 3. Veri Setleri
```
ğŸ“Š ImageNet           - Genel nesneler
ğŸ“Š Kaggle Datasets    - Makine Ã¶ÄŸrenmesi veri setleri
ğŸ“Š Google Dataset Search - Arama motoru
```

### 4. Kendi KaynaklarÄ±nÄ±z
```
ğŸ“¸ Telefon kamerasÄ±
ğŸ“¸ Workshop/atÃ¶lye
ğŸ“¸ ArkadaÅŸlardan Ã¶dÃ¼nÃ§
ğŸ“¸ Yerel donanÄ±m maÄŸazasÄ± (izinle)
```

---

## ğŸ› ï¸ AdÄ±m AdÄ±m: Ä°lk 10 GÃ¶rÃ¼ntÃ¼ Ekleyelim

### Ã–rnek: Vida iÃ§in gÃ¶rÃ¼ntÃ¼ toplama

```bash
# 1. Google GÃ¶rseller'de ara
Arama terimleri:
- "M8 hex bolt"
- "machine screw"
- "threaded fastener"
- "vida makine parÃ§asÄ±"

# 2. 10 gÃ¶rÃ¼ntÃ¼ indir
training_data/vida/vida_01.jpg
training_data/vida/vida_02.jpg
...
training_data/vida/vida_10.jpg

# 3. Kontrol et
ls training_data/vida/ | wc -l
# Ã‡Ä±ktÄ±: 10

# 4. TÃ¼m parÃ§alar iÃ§in tekrarla
```

### HÄ±zlÄ± Test Script'i

Bir scriptle gÃ¶rÃ¼ntÃ¼ sayÄ±larÄ±nÄ± kontrol edin:

```bash
# GÃ¶rÃ¼ntÃ¼ sayÄ±larÄ±nÄ± say
for dir in training_data/*/; do
    count=$(find "$dir" -type f \( -name "*.jpg" -o -name "*.png" \) | wc -l)
    echo "$(basename $dir): $count gÃ¶rÃ¼ntÃ¼"
done
```

---

## ğŸ¤– Veri ArtÄ±rma (Data Augmentation)

Az gÃ¶rÃ¼ntÃ¼nÃ¼z varsa, veri artÄ±rma ile Ã§oÄŸaltabilirsiniz:

### Script OluÅŸturun: `augment_data.py`

```python
from PIL import Image
import os
from pathlib import Path

def augment_image(img_path, output_dir):
    """Bir gÃ¶rÃ¼ntÃ¼yÃ¼ Ã§eÅŸitli ÅŸekillerde dÃ¶nÃ¼ÅŸtÃ¼r"""
    img = Image.open(img_path)
    base_name = Path(img_path).stem
    
    # 1. Orijinal
    img.save(f"{output_dir}/{base_name}_original.jpg")
    
    # 2. 90Â° dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ
    img.rotate(90).save(f"{output_dir}/{base_name}_rot90.jpg")
    
    # 3. 180Â° dÃ¶ndÃ¼rÃ¼lmÃ¼ÅŸ
    img.rotate(180).save(f"{output_dir}/{base_name}_rot180.jpg")
    
    # 4. Yatay Ã§evrilmiÅŸ
    img.transpose(Image.FLIP_LEFT_RIGHT).save(
        f"{output_dir}/{base_name}_flip.jpg"
    )
    
    # 5. ParlaklÄ±k artÄ±rÄ±lmÄ±ÅŸ
    from PIL import ImageEnhance
    enhancer = ImageEnhance.Brightness(img)
    enhancer.enhance(1.3).save(f"{output_dir}/{base_name}_bright.jpg")

# KullanÄ±m
for parca_dir in Path('training_data').iterdir():
    if parca_dir.is_dir():
        for img in parca_dir.glob('*.jpg'):
            augment_image(img, parca_dir)
```

**SonuÃ§:** 10 gÃ¶rÃ¼ntÃ¼ â†’ 50 gÃ¶rÃ¼ntÃ¼ (5x artÄ±ÅŸ)

---

## ğŸ“ˆ Model EÄŸitimi

GÃ¶rÃ¼ntÃ¼leri ekledikten sonra:

### 1. Veri MiktarÄ±nÄ± Kontrol Edin
```bash
python test_system.py
```

### 2. Model EÄŸitin
```bash
# KÃ¼Ã§Ã¼k veri seti iÃ§in (10-50 gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f)
python train_model.py --mode train --data_dir ./training_data --epochs 20

# Orta veri seti iÃ§in (50-100 gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f)
python train_model.py --mode train --data_dir ./training_data --epochs 30 --batch_size 16

# BÃ¼yÃ¼k veri seti iÃ§in (100+ gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f)
python train_model.py --mode train --data_dir ./training_data --epochs 50 --batch_size 32
```

### 3. Model Test Edin
```bash
python train_model.py --mode test --model_path best_model.pth --image test_images/test_vida.jpg
```

### 4. Streamlit'te KullanÄ±n
```bash
streamlit run app.py
# "Deep Learning" veya "Hibrit" modunu seÃ§in
```

---

## âœ… Checklist: BaÅŸlamadan Ã–nce

- [ ] `training_data/` klasÃ¶rlerinin var olduÄŸunu kontrol ettim
- [ ] Her parÃ§a iÃ§in en az 10 gÃ¶rÃ¼ntÃ¼ hedefi belirledim
- [ ] GÃ¶rÃ¼ntÃ¼ kaynaklarÄ±nÄ± araÅŸtÄ±rdÄ±m
- [ ] Ä°lk parÃ§a iÃ§in 5-10 gÃ¶rÃ¼ntÃ¼ indirdim
- [ ] GÃ¶rÃ¼ntÃ¼lerin doÄŸru klasÃ¶re gittiÄŸini doÄŸruladÄ±m
- [ ] `test_system.py` ile kontrol ettim
- [ ] Model eÄŸitimi iÃ§in hazÄ±rÄ±m

---

## ğŸ¯ HÄ±zlÄ± BaÅŸlangÄ±Ã§ PlanÄ± (Ã–NERÄ°LEN)

### BugÃ¼n (1-2 saat)
1. âœ… 3 parÃ§a seÃ§in (vida, somun, rulman)
2. âœ… Her biri iÃ§in 10 gÃ¶rÃ¼ntÃ¼ toplayÄ±n (Google'dan)
3. âœ… `training_data/` klasÃ¶rlerine koyun
4. âœ… Ä°lk eÄŸitimi yapÄ±n (10 epoch)

### Bu Hafta
1. âœ… 6 parÃ§aya Ã§Ä±karÄ±n
2. âœ… Her biri iÃ§in 30 gÃ¶rÃ¼ntÃ¼
3. âœ… Veri artÄ±rma uygulayÄ±n
4. âœ… 30 epoch eÄŸitim

### Bu Ay
1. âœ… TÃ¼m 10 parÃ§a
2. âœ… Her biri iÃ§in 100+ gÃ¶rÃ¼ntÃ¼
3. âœ… Profesyonel model eÄŸitimi
4. âœ… GerÃ§ek dÃ¼nya testleri

---

## ğŸ†˜ SÄ±k Sorulan Sorular

### S: KaÃ§ gÃ¶rÃ¼ntÃ¼ yeterli?
**C:** 
- Minimum: 10-20 (test iÃ§in)
- Ä°yi: 50-100 (kullanÄ±labilir)
- MÃ¼kemmel: 200+ (profesyonel)

### S: GÃ¶rÃ¼ntÃ¼ler birbirine Ã§ok mu benzemeli?
**C:** HAYIR! Ã‡eÅŸitlilik Ã¶nemli:
- FarklÄ± aÃ§Ä±lar
- FarklÄ± arka planlar
- FarklÄ± aydÄ±nlatma
- FarklÄ± parÃ§a tipleri (M6, M8, M10 vidalar)

### S: Renkli mi gri tonlamalÄ± mÄ±?
**C:** Renkli (RGB) tercih edin. Sistem otomatik dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

### S: Boyut Ã¶nemli mi?
**C:** 500x500 ile 2000x2000 arasÄ± ideal. Ã‡ok kÃ¼Ã§Ã¼k veya Ã§ok bÃ¼yÃ¼k resimlerden kaÃ§Ä±nÄ±n.

### S: Ä°nternetten aldÄ±ÄŸÄ±m gÃ¶rÃ¼ntÃ¼leri kullanabilir miyim?
**C:** Evet, ancak:
- Telif hakkÄ±na dikkat edin
- Ticari kullanÄ±m iÃ§in lisans kontrol edin
- EÄŸitim/araÅŸtÄ±rma iÃ§in genelde sorun olmaz

---

## ğŸ“ YardÄ±m

Sorun yaÅŸarsanÄ±z:

```bash
# GÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±nÄ± kontrol
python test_system.py

# GÃ¶rÃ¼ntÃ¼ formatÄ±nÄ± kontrol
file training_data/vida/*.jpg

# KlasÃ¶r yapÄ±sÄ±nÄ± kontrol
tree training_data/
```

---

**ğŸ‰ Ä°YÄ° ÅANSLAR!** Ä°lk 10 gÃ¶rÃ¼ntÃ¼ ile baÅŸlayÄ±n, sistem Ã§alÄ±ÅŸmaya baÅŸladÄ±ÄŸÄ±nda daha fazla eklersiniz!

## 6. VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md

# ğŸ—ºï¸ VERÄ° TOPLAMA YOL HARÄ°TASI

Makine parÃ§asÄ± tanÄ±ma sisteminiz iÃ§in kapsamlÄ± bir bilgi tabanÄ± oluÅŸturma rehberi.

---

## ğŸ“… AÅAMA 1: HIZLI PROTOTIP (1-3 GÃœN)

### Hedef: Sistemin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek

#### AdÄ±m 1.1: Temel Referans GÃ¶rÃ¼ntÃ¼ler (2 saat)
```bash
# Her parÃ§a iÃ§in 3-5 Ã¶rnek gÃ¶rÃ¼ntÃ¼
referans_gorseller/
â”œâ”€â”€ vida/         (3-5 gÃ¶rÃ¼ntÃ¼)
â”œâ”€â”€ somun/        (3-5 gÃ¶rÃ¼ntÃ¼)
â”œâ”€â”€ rulman/       (3-5 gÃ¶rÃ¼ntÃ¼)
â””â”€â”€ ...
```

**Nereden Bulabilirsiniz:**
1. **Google GÃ¶rseller**: "M8 vida", "altÄ±gen somun", vb.
   - SaÄŸ tÄ±k â†’ Resmi farklÄ± kaydet
   - Her parÃ§a iÃ§in 3-5 farklÄ± aÃ§Ä±dan
   
2. **Ãœcretsiz Stok FotoÄŸraf Siteleri**:
   - Unsplash.com
   - Pexels.com
   - Pixabay.com
   - Freepik.com (bazÄ± Ã¼cretsiz)

3. **Telefon KameranÄ±z**:
   - Beyaz/gri arka plan
   - Ä°yi aydÄ±nlatma
   - FarklÄ± aÃ§Ä±lar

#### AdÄ±m 1.2: Test (10 dakika)
```bash
python test_system.py
streamlit run app.py
```

**Beklenen SonuÃ§:**
- âœ… Feature matching aktif
- ğŸ“Š %60-70 doÄŸruluk (yeterli baÅŸlangÄ±Ã§ iÃ§in)

#### AdÄ±m 1.3: Ä°lk Geri Bildirim (1 gÃ¼n)
- ArkadaÅŸlara test ettirin
- Hangi parÃ§alar karÄ±ÅŸÄ±yor?
- Hangi aÃ§Ä±lar zor?

---

## ğŸ“… AÅAMA 2: VERÄ° GENÄ°ÅLETME (1-2 HAFTA)

### Hedef: Her parÃ§a iÃ§in 20-30 gÃ¶rÃ¼ntÃ¼

#### AdÄ±m 2.1: Web Scraping (Otomatik) - 1 gÃ¼n

**Script ile toplu indirme:**
```python
# web_scraper.py dosyasÄ± oluÅŸturun
from google_images_download import google_images_download

parcalar = ['vida', 'somun', 'rulman', 'kayÄ±ÅŸ', 'diÅŸli']
response = google_images_download.googleimagesdownload()

for parca in parcalar:
    arguments = {
        "keywords": f"makine {parca}, mechanical {parca}",
        "limit": 30,
        "format": "jpg",
        "output_directory": "referans_gorseller",
        "image_directory": parca,
        "size": "medium",
        "aspect_ratio": "square"
    }
    paths = response.download(arguments)
    print(f"{parca}: Ä°ndirildi")
```

**Kurulum:**
```bash
pip install google_images_download
python web_scraper.py
```

#### AdÄ±m 2.2: Online Kataloglar - 2 saat
**Ã–nerilen Kaynaklar:**
1. **Grainger.com** - EndÃ¼striyel parÃ§a kataloglarÄ±
2. **McMaster-Carr** - Teknik Ã§izimler ve fotoÄŸraflar
3. **RS Components** - Elektronik ve mekanik parÃ§alar
4. **Digikey** - Elektronik komponentler
5. **Alibaba/AliExpress** - ÃœrÃ¼n fotoÄŸraflarÄ±

#### AdÄ±m 2.3: Manuel FotoÄŸraf Ã‡ekimi - 1-2 saat
**Profesyonel FotoÄŸraf Ä°puÃ§larÄ±:**
```
SETUP:
â”œâ”€â”€ Beyaz A4 kaÄŸÄ±t (arka plan)
â”œâ”€â”€ LED lamba (gÃ¶lgesiz aydÄ±nlatma)
â”œâ”€â”€ Telefon kamerasÄ± (en az 8MP)
â””â”€â”€ Tripod (sabit Ã§ekim)

AÃ‡ILAR:
â”œâ”€â”€ Ãœstten (90Â°)
â”œâ”€â”€ Yan (45Â°)
â”œâ”€â”€ Ã‡apraz (30Â°)
â”œâ”€â”€ YakÄ±n plan
â””â”€â”€ Uzak plan
```

**Ã–rnek Ã‡ekim Listesi:**
```
vida_001.jpg - Ãœstten, dÃ¼z
vida_002.jpg - 45Â° aÃ§Ä±
vida_003.jpg - Yan gÃ¶rÃ¼nÃ¼m
vida_004.jpg - YakÄ±n plan (diÅŸler)
vida_005.jpg - 3-4 vida bir arada
```

---

## ğŸ“… AÅAMA 3: KALÄ°TE KONTROL (2-3 GÃœN)

### Hedef: Kalitesiz gÃ¶rÃ¼ntÃ¼leri temizlemek

#### AdÄ±m 3.1: Otomatik Filtreleme
```python
# image_quality_check.py
from PIL import Image
import os

def check_image_quality(folder):
    for root, dirs, files in os.walk(folder):
        for file in files:
            if file.endswith(('.jpg', '.png')):
                img_path = os.path.join(root, file)
                img = Image.open(img_path)
                
                # Boyut kontrolÃ¼
                if img.width < 200 or img.height < 200:
                    print(f"âŒ KÃ¼Ã§Ã¼k: {img_path}")
                    
                # Aspect ratio kontrolÃ¼
                ratio = img.width / img.height
                if ratio > 3 or ratio < 0.33:
                    print(f"âš ï¸  OrantÄ±sÄ±z: {img_path}")
                
                # Dosya boyutu
                size_kb = os.path.getsize(img_path) / 1024
                if size_kb < 10:
                    print(f"âŒ Ã‡ok kÃ¼Ã§Ã¼k dosya: {img_path}")

check_image_quality('referans_gorseller')
```

#### AdÄ±m 3.2: Manuel Ä°nceleme (1 saat)
ÅunlarÄ± kontrol edin:
- âœ… ParÃ§a net gÃ¶rÃ¼nÃ¼yor mu?
- âœ… Arka plan temiz mi?
- âœ… DoÄŸru etiketlenmiÅŸ mi?
- âŒ Filigran/logo var mÄ±?

#### AdÄ±m 3.3: Temizleme
```bash
# KÃ¼Ã§Ã¼k gÃ¶rÃ¼ntÃ¼leri sil
find referans_gorseller -type f -size -10k -delete

# Duplicate kontrol
pip install imagededup
```

---

## ğŸ“… AÅAMA 4: VERÄ° ARTIRMA (1 GÃœN)

### Hedef: 20 gÃ¶rÃ¼ntÃ¼yÃ¼ 100'e Ã§Ä±karmak

#### Script ile Otomatik Augmentation:
```python
# data_augmentation.py
from torchvision import transforms
from PIL import Image
import os

augmentation = transforms.Compose([
    transforms.RandomRotation(30),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),
    transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0)),
])

def augment_folder(input_folder, output_folder, count=5):
    os.makedirs(output_folder, exist_ok=True)
    
    for img_file in os.listdir(input_folder):
        if not img_file.endswith(('.jpg', '.png')):
            continue
            
        img_path = os.path.join(input_folder, img_file)
        img = Image.open(img_path)
        
        # Orijinali kopyala
        img.save(os.path.join(output_folder, img_file))
        
        # Augmented versiyonlar
        for i in range(count):
            aug_img = augmentation(img)
            name, ext = os.path.splitext(img_file)
            aug_img.save(os.path.join(output_folder, f"{name}_aug{i}{ext}"))
        
        print(f"âœ“ {img_file}: 1 + {count} = {count+1} gÃ¶rÃ¼ntÃ¼")

# KullanÄ±m
augment_folder('referans_gorseller/vida', 'training_data/vida', count=5)
```

**Ã‡alÄ±ÅŸtÄ±r:**
```bash
python data_augmentation.py
```

**SonuÃ§:**
- 20 gerÃ§ek gÃ¶rÃ¼ntÃ¼ â†’ 120 toplam gÃ¶rÃ¼ntÃ¼ (20 + 100 augmented)

---

## ğŸ“… AÅAMA 5: ETÄ°KETLEME VE ORGANÄ°ZASYON (1-2 GÃœN)

### AdÄ±m 5.1: KlasÃ¶r YapÄ±sÄ±nÄ± DÃ¼zenle
```
training_data/
â”œâ”€â”€ vida/
â”‚   â”œâ”€â”€ m3_vida_001.jpg
â”‚   â”œâ”€â”€ m3_vida_002.jpg
â”‚   â”œâ”€â”€ m8_vida_001.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ somun/
â”‚   â”œâ”€â”€ altigen_somun_001.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ rulman/
    â”œâ”€â”€ 608_rulman_001.jpg
    â””â”€â”€ ...
```

### AdÄ±m 5.2: Metadata OluÅŸtur
```python
# create_metadata.py
import json
import os
from PIL import Image

metadata = {}

for parca in os.listdir('training_data'):
    parca_path = os.path.join('training_data', parca)
    if not os.path.isdir(parca_path):
        continue
    
    images = []
    for img_file in os.listdir(parca_path):
        if img_file.endswith(('.jpg', '.png')):
            img_path = os.path.join(parca_path, img_file)
            img = Image.open(img_path)
            
            images.append({
                'filename': img_file,
                'width': img.width,
                'height': img.height,
                'size_kb': os.path.getsize(img_path) / 1024
            })
    
    metadata[parca] = {
        'count': len(images),
        'images': images
    }

with open('dataset_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)

print("Metadata oluÅŸturuldu!")
```

---

## ğŸ“… AÅAMA 6: MODEL EÄÄ°TÄ°MÄ° (1-2 GÃœN)

### AdÄ±m 6.1: Veri Setini BÃ¶l
```python
# split_dataset.py
import os
import shutil
import random

def split_dataset(source, train_ratio=0.8):
    for parca in os.listdir(source):
        parca_path = os.path.join(source, parca)
        if not os.path.isdir(parca_path):
            continue
        
        images = [f for f in os.listdir(parca_path) if f.endswith(('.jpg', '.png'))]
        random.shuffle(images)
        
        split_idx = int(len(images) * train_ratio)
        train_imgs = images[:split_idx]
        val_imgs = images[split_idx:]
        
        # Train klasÃ¶rÃ¼
        train_dir = f'dataset/train/{parca}'
        os.makedirs(train_dir, exist_ok=True)
        
        # Val klasÃ¶rÃ¼
        val_dir = f'dataset/val/{parca}'
        os.makedirs(val_dir, exist_ok=True)
        
        for img in train_imgs:
            shutil.copy(
                os.path.join(parca_path, img),
                os.path.join(train_dir, img)
            )
        
        for img in val_imgs:
            shutil.copy(
                os.path.join(parca_path, img),
                os.path.join(val_dir, img)
            )
        
        print(f"{parca}: {len(train_imgs)} train, {len(val_imgs)} val")

split_dataset('training_data')
```

### AdÄ±m 6.2: Model EÄŸit
```bash
python train_model.py \
    --mode train \
    --data_dir ./dataset/train \
    --epochs 50 \
    --batch_size 32 \
    --lr 0.001
```

### AdÄ±m 6.3: Model DeÄŸerlendir
```bash
python train_model.py \
    --mode test \
    --model_path best_model.pth \
    --test_image ./dataset/val/vida/test1.jpg
```

---

## ğŸ“… AÅAMA 7: KULLANICI GERÄ° BÄ°LDÄ°RÄ°MÄ° (SÃœREKLÄ°)

### Feedback Sistemi Kur
```python
# app.py iÃ§ine ekleyin
if st.button("âŒ YanlÄ±ÅŸ TanÄ±ma"):
    feedback = {
        'image': uploaded_file.name,
        'predicted': parca_adi,
        'user_says': st.selectbox("DoÄŸrusu ne?", sistem.parca_veritabani.keys())
    }
    
    # CSV'ye kaydet
    import csv
    with open('feedback.csv', 'a') as f:
        writer = csv.DictWriter(f, fieldnames=['image', 'predicted', 'user_says'])
        writer.writerow(feedback)
    
    st.success("Geri bildirim kaydedildi!")
```

### AylÄ±k Ä°yileÅŸtirme DÃ¶ngÃ¼sÃ¼
```bash
# 1. Feedback topla (30 gÃ¼n)
# 2. YanlÄ±ÅŸ tanÄ±malarÄ± analiz et
# 3. O parÃ§alar iÃ§in daha fazla veri topla
# 4. Yeniden eÄŸit
# 5. Deploy et
```

---

## ğŸ“Š HEDEF VERÄ° MÄ°KTARLARI

| AÅŸama | GÃ¶rÃ¼ntÃ¼/SÄ±nÄ±f | Toplam (10 sÄ±nÄ±f) | DoÄŸruluk Beklentisi |
|-------|---------------|-------------------|---------------------|
| **Prototip** | 3-5 | 30-50 | %60-70 (FM) |
| **Beta** | 20-30 | 200-300 | %70-80 (FM) |
| **Production v1** | 50-100 | 500-1000 | %85-90 (DL) |
| **Production v2** | 100-200 | 1000-2000 | %90-95 (Hibrit) |
| **Enterprise** | 200-500 | 2000-5000 | %95-98 (Ensemble) |

---

## ğŸ› ï¸ ARAÃ‡LAR VE KAYNAKLAR

### GÃ¶rÃ¼ntÃ¼ Toplama
- **google-images-download**: Otomatik indirme
- **Selenium**: Web scraping
- **Beautiful Soup**: HTML parsing
- **Scrapy**: Profesyonel scraping

### Etiketleme
- **Labelbox**: Web tabanlÄ± (Ã¼cretsiz plan)
- **LabelImg**: Desktop app
- **CVAT**: AÃ§Ä±k kaynak
- **Roboflow**: Veri yÃ¶netimi + etiketleme

### Veri ArtÄ±rma
- **Albumentations**: GeliÅŸmiÅŸ augmentation
- **imgaug**: Ã‡eÅŸitli augmentation
- **Torchvision transforms**: Basit augmentation

### Kalite Kontrol
- **ImageMagick**: Batch iÅŸlemler
- **ImageDedupe**: Duplicate silme
- **PIL/Pillow**: Python ile kontrol

---

## ğŸ“… ZAMAN Ã‡Ä°ZELGESÄ° Ã–ZETÄ°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GÃœN 1-3: HÄ±zlÄ± Prototip                   â”‚
â”‚  â””â”€ 3-5 gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f                       â”‚
â”‚  â””â”€ Feature matching test                   â”‚
â”‚  Ã‡Ä±ktÄ±: Ã‡alÄ±ÅŸan demo                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 1-2: Veri Toplama                   â”‚
â”‚  â””â”€ Web scraping                            â”‚
â”‚  â””â”€ Manuel fotoÄŸraf                          â”‚
â”‚  â””â”€ 20-30 gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f                     â”‚
â”‚  Ã‡Ä±ktÄ±: 200-300 toplam gÃ¶rÃ¼ntÃ¼              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 2-3: Kalite & ArtÄ±rma               â”‚
â”‚  â””â”€ Filtreleme ve temizleme                 â”‚
â”‚  â””â”€ Data augmentation                        â”‚
â”‚  â””â”€ 100+ gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f                      â”‚
â”‚  Ã‡Ä±ktÄ±: 1000+ eÄŸitim verisi                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 4: Model EÄŸitimi                    â”‚
â”‚  â””â”€ Transfer learning                        â”‚
â”‚  â””â”€ Validation ve test                       â”‚
â”‚  Ã‡Ä±ktÄ±: best_model.pth (%85-90)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SÃœREKLÄ°: Ä°yileÅŸtirme                      â”‚
â”‚  â””â”€ KullanÄ±cÄ± feedback                       â”‚
â”‚  â””â”€ AylÄ±k yeniden eÄŸitim                     â”‚
â”‚  Ã‡Ä±ktÄ±: %95+ doÄŸruluk                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’° MALÄ°YET TAHMÄ°NÄ°

### Ãœcretsiz YÃ¶ntem:
- âœ… Google GÃ¶rseller (manuel)
- âœ… Kendi fotoÄŸraflarÄ±nÄ±z
- âœ… AÃ§Ä±k kaynak araÃ§lar
- **Toplam: 0 TL**

### YarÄ±-Otomatik:
- âœ… Web scraping (Ã¼cretsiz)
- âœ… Labelbox Ã¼cretsiz plan
- âœ… Roboflow Ã¼cretsiz tier
- **Toplam: 0-500 TL**

### Profesyonel:
- ğŸ’° Mechanical Turk (etiketleme): ~1000 TL
- ğŸ’° Shutterstock/Getty: ~2000 TL
- ğŸ’° GPU Cloud (eÄŸitim): ~500 TL/ay
- **Toplam: 3500-5000 TL**

---

## âœ… KONTROL LÄ°STESÄ°

### Hafta 1
- [ ] 5 farklÄ± parÃ§a seÃ§ildi
- [ ] ParÃ§a baÅŸÄ±na 10 gÃ¶rÃ¼ntÃ¼ toplandÄ±
- [ ] Feature matching test edildi
- [ ] Ä°lk demo hazÄ±r

### Hafta 2
- [ ] Web scraping scripti Ã§alÄ±ÅŸÄ±yor
- [ ] 300+ gÃ¶rÃ¼ntÃ¼ toplandÄ±
- [ ] Kalite kontrol yapÄ±ldÄ±
- [ ] Augmentation test edildi

### Hafta 3
- [ ] 1000+ eÄŸitim verisi hazÄ±r
- [ ] Train/val/test split yapÄ±ldÄ±
- [ ] Metadata oluÅŸturuldu

### Hafta 4
- [ ] Model eÄŸitimi tamamlandÄ±
- [ ] %85+ validation accuracy
- [ ] Hibrit sistem test edildi
- [ ] Production'a deploy edildi

---

**BAÅARILAR! ğŸš€**

SorularÄ±nÄ±z iÃ§in: Issues aÃ§abilir veya doÄŸrudan sorabilirsiniz!

## 7. YONTEM_KARSILASTIRMA.md

# ğŸ¯ GÃ¶rÃ¼ntÃ¼ TanÄ±ma YÃ¶ntemleri - DetaylÄ± KarÅŸÄ±laÅŸtÄ±rma ve Ã–neriler

## ğŸ“Š Ä°ki Ana YaklaÅŸÄ±m

### 1ï¸âƒ£ Feature Matching (GÃ¶rÃ¼ntÃ¼ Benzerlik TabanlÄ±)

#### NasÄ±l Ã‡alÄ±ÅŸÄ±r?
```
Referans GÃ¶rÃ¼ntÃ¼ â†’ Ã–zellik Ã‡Ä±karma â†’ VeritabanÄ±na Kaydet
Test GÃ¶rÃ¼ntÃ¼ â†’ Ã–zellik Ã‡Ä±karma â†’ Referanslarla KarÅŸÄ±laÅŸtÄ±r â†’ En Benzer Bulundu!
```

#### KullanÄ±lan Teknikler:
- **SIFT/ORB**: GÃ¶rÃ¼ntÃ¼deki benzersiz noktalarÄ± (keypoints) bulur
- **Histogram**: Renk daÄŸÄ±lÄ±mÄ±nÄ± karÅŸÄ±laÅŸtÄ±rÄ±r
- **Hu Moments**: Åekil Ã¶zelliklerini analiz eder
- **SSIM**: YapÄ±sal benzerliÄŸi Ã¶lÃ§er

#### Avantajlar âœ…
1. **HÄ±zlÄ± BaÅŸlangÄ±Ã§**: EÄŸitim gerektirmez
2. **Az Veri**: ParÃ§a baÅŸÄ±na 3-5 gÃ¶rÃ¼ntÃ¼ yeterli
3. **Kolay GeniÅŸletme**: Yeni parÃ§a eklemek Ã§ok kolay
4. **Åeffaf**: Neden o sonucu verdiÄŸi anlaÅŸÄ±lÄ±r
5. **DonanÄ±m**: GPU gerektirmez

#### Dezavantajlar âŒ
1. **AÃ§Ä± Hassasiyeti**: FarklÄ± aÃ§Ä±lardan zorlanÄ±r
2. **IÅŸÄ±k DeÄŸiÅŸimi**: AydÄ±nlatma farklÄ±lÄ±klarÄ±nda performans dÃ¼ÅŸer
3. **Benzer ParÃ§alar**: Vida vs somun gibi benzer parÃ§alarÄ± karÄ±ÅŸtÄ±rabilir
4. **Arka Plan**: KarmaÅŸÄ±k arka planlarda zorlanÄ±r
5. **DoÄŸruluk**: %60-75 civarÄ±

#### En Ä°yi KullanÄ±m SenaryolarÄ±:
- âœ… Prototip aÅŸamasÄ±
- âœ… SÄ±nÄ±rlÄ± veri var
- âœ… HÄ±zlÄ± sonuÃ§ gerekli
- âœ… Standart koÅŸullar (sabit aÃ§Ä±, Ä±ÅŸÄ±k)
- âœ… Ã‡ok farklÄ± gÃ¶rÃ¼nen parÃ§alar

---

### 2ï¸âƒ£ Deep Learning (CNN - EÄŸitilmiÅŸ Model)

#### NasÄ±l Ã‡alÄ±ÅŸÄ±r?
```
Veri Toplama â†’ Etiketleme â†’ Model EÄŸitimi â†’ Test â†’ Deploy
Test GÃ¶rÃ¼ntÃ¼ â†’ Model â†’ SÄ±nÄ±flandÄ±rma â†’ GÃ¼ven Skoru
```

#### KullanÄ±lan Mimariler:
- **ResNet**: Transfer learning iÃ§in ideal
- **EfficientNet**: HÄ±z/doÄŸruluk dengesi
- **MobileNet**: Mobil cihazlar iÃ§in
- **Vision Transformer**: En yeni teknoloji

#### Avantajlar âœ…
1. **YÃ¼ksek DoÄŸruluk**: %90-98 doÄŸruluk mÃ¼mkÃ¼n
2. **Robust**: AÃ§Ä±, Ä±ÅŸÄ±k, arka plan deÄŸiÅŸimlerine dayanÄ±klÄ±
3. **Otomatik Ã–zellik**: Kendisi Ã¶nemli Ã¶zellikleri Ã¶ÄŸrenir
4. **Ã–lÃ§eklenebilir**: 100+ sÄ±nÄ±f iÃ§in ideal
5. **Transfer Learning**: Ã–nceden eÄŸitilmiÅŸ modeller kullanÄ±labilir

#### Dezavantajlar âŒ
1. **Veri Ä°htiyacÄ±**: SÄ±nÄ±f baÅŸÄ±na 100-1000+ gÃ¶rÃ¼ntÃ¼ gerekir
2. **EÄŸitim SÃ¼resi**: Saatler veya gÃ¼nler sÃ¼rebilir
3. **GPU Gereksinimi**: EÄŸitim iÃ§in GPU ÅŸart
4. **Yeni SÄ±nÄ±f**: Yeni parÃ§a iÃ§in yeniden eÄŸitim gerekir
5. **Black Box**: Karar sÃ¼reci anlaÅŸÄ±lmasÄ± zor

#### En Ä°yi KullanÄ±m SenaryolarÄ±:
- âœ… YÃ¼ksek doÄŸruluk kritik
- âœ… Ã‡ok fazla veri var
- âœ… Ã‡eÅŸitli aÃ§Ä±lar/koÅŸullar
- âœ… Production ortam
- âœ… Benzer gÃ¶rÃ¼nen parÃ§alar

---

## ğŸ¯ HANGÄ°SÄ° DAHA MANTIKLI?

### Tek Kelime: **HÄ°BRÄ°T!** ğŸš€

Her iki yÃ¶ntemin de gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nleri var. **En iyi Ã§Ã¶zÃ¼m ikisini birleÅŸtirmektir!**

## ğŸ’¡ Hibrit YaklaÅŸÄ±m Stratejileri

### Strateji 1: **Cascading (BasamaklÄ±)**
```
1. Deep Learning ile tahmin yap
2. GÃ¼ven > 0.8 ise â†’ SONUÃ‡
3. GÃ¼ven < 0.8 ise â†’ Feature Matching de kullan
4. Ä°ki sonucu karÅŸÄ±laÅŸtÄ±r â†’ En iyi SONUÃ‡
```

**Avantaj**: HÄ±zlÄ± + gÃ¼venilir
**KullanÄ±m**: Ã‡oÄŸu durumda ideal

### Strateji 2: **Ensemble (BirleÅŸtirme)**
```
1. Deep Learning skoru: 0.7 * DL_skor
2. Feature Matching skoru: 0.3 * FM_skor
3. Toplam skor = DL + FM
4. En yÃ¼ksek skor â†’ SONUÃ‡
```

**Avantaj**: En yÃ¼ksek doÄŸruluk
**KullanÄ±m**: Kritik uygulamalar

### Strateji 3: **Voting (Oylama)**
```
1. Her yÃ¶ntem ayrÄ± tahmin yapar
2. Her yÃ¶ntemin aÄŸÄ±rlÄ±ÄŸÄ± farklÄ±
3. Ã‡oÄŸunluk kararÄ± alÄ±nÄ±r
```

**Avantaj**: Hataya toleranslÄ±
**KullanÄ±m**: Medikal, gÃ¼venlik kritik

---

## ğŸ“ˆ Proje AÅŸamalarÄ±na GÃ¶re Ã–neriler

### ğŸŒ± BaÅŸlangÄ±Ã§ AÅŸamasÄ± (0-1 ay)
**Ã–neri**: Feature Matching
- 5-10 referans gÃ¶rÃ¼ntÃ¼ topla
- HÄ±zlÄ±ca test et
- KullanÄ±cÄ± geri bildirimi al

**Kod**:
```python
from feature_matcher import FeatureMatchingTanima

matcher = FeatureMatchingTanima('./referans_gorseller')
sonuc = matcher.tanima_yap('test.jpg')
```

### ğŸŒ¿ GeliÅŸtirme AÅŸamasÄ± (1-3 ay)
**Ã–neri**: Veri toplama + Transfer Learning
- KullanÄ±cÄ±lardan veri topla
- Her parÃ§a iÃ§in 50-100 gÃ¶rÃ¼ntÃ¼
- Transfer learning ile model eÄŸit

**Kod**:
```bash
python train_model.py --mode train \
    --data_dir ./training_data \
    --epochs 25 \
    --batch_size 32
```

### ğŸŒ³ Production AÅŸamasÄ± (3+ ay)
**Ã–neri**: Hibrit Sistem
- EÄŸitilmiÅŸ model + Feature matching
- Auto mod ile en iyi sonuÃ§
- SÃ¼rekli iyileÅŸtirme

**Kod**:
```python
from hybrid_detector import HibritTanima

sistem = HibritTanima(
    model_path='best_model.pth',
    referans_klasor='./referans_gorseller',
    mod='auto'
)
sonuc = sistem.tanima_yap('test.jpg')
```

---

## ğŸª GerÃ§ek DÃ¼nya SenaryolarÄ±

### Senaryo 1: 3D Modelleme YazÄ±lÄ±mÄ± Entegrasyonu
**Durum**: KullanÄ±cÄ± modelde bir parÃ§a seÃ§iyor, ne olduÄŸunu Ã¶ÄŸrenmek istiyor

**Ã‡Ã¶zÃ¼m**: Hibrit Auto Mod
- HÄ±zlÄ± sonuÃ§
- YÃ¼ksek doÄŸruluk
- DÃ¼ÅŸÃ¼k gÃ¼vende alternatif Ã¶nerir

```python
# 3D model'den screenshot al
screenshot = capture_3d_viewport()

# TanÄ±
sistem = HibritTanima(mod='auto')
sonuc = sistem.tanima_yap(screenshot)

# KullanÄ±cÄ±ya gÃ¶ster
show_info_panel(sonuc['parca'], sonuc['guven'])
```

### Senaryo 2: Mobil Uygulama (AR ile ParÃ§a TanÄ±ma)
**Durum**: KullanÄ±cÄ± telefon kamerasÄ± ile parÃ§ayÄ± tarÄ±yor

**Ã‡Ã¶zÃ¼m**: Optimized Deep Learning
- MobileNet modeli
- On-device inference
- < 100ms yanÄ±t sÃ¼resi

```python
# Mobil iÃ§in optimize edilmiÅŸ model
model = MobileNetV3(num_classes=20)
model.load_state_dict('mobile_optimized.pth')

# Quantization (boyut azaltma)
quantized_model = torch.quantization.quantize_dynamic(
    model, {nn.Linear}, dtype=torch.qint8
)
```

### Senaryo 3: EndÃ¼striyel Ãœretim HattÄ±
**Durum**: KonveyÃ¶r bandÄ±nda parÃ§alarÄ± otomatik sÄ±nÄ±flandÄ±rma

**Ã‡Ã¶zÃ¼m**: Ensemble + Kalite KontrolÃ¼
- Ã‡ok yÃ¼ksek doÄŸruluk gerekli
- Her iki yÃ¶ntemi de kullan
- DÃ¼ÅŸÃ¼k gÃ¼vende insan onayÄ± iste

```python
sistem = HibritTanima(mod='ensemble')
sonuc = sistem.tanima_yap(konveyor_goruntusu)

if sonuc['guven'] > 0.95:
    otomatik_siniflandir(sonuc['parca'])
elif sonuc['guven'] > 0.7:
    operator_onayi_iste(sonuc)
else:
    manuel_inceleme_gonder()
```

---

## ğŸ’¾ Veri Toplama Stratejileri

### 1. Web Scraping
```python
from google_images_download import google_images_download

response = google_images_download.googleimagesdownload()
arguments = {
    "keywords": "M8 vida, hex bolt",
    "limit": 100,
    "format": "jpg"
}
paths = response.download(arguments)
```

### 2. Sentetik Veri (Data Augmentation)
```python
from torchvision import transforms

augment = transforms.Compose([
    transforms.RandomRotation(30),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(0.3, 0.3, 0.3),
    transforms.RandomPerspective(0.2),
    transforms.GaussianBlur(3),
])

# 1 gÃ¶rÃ¼ntÃ¼den 20 varyasyon
for i in range(20):
    aug_image = augment(original_image)
    aug_image.save(f'augmented_{i}.jpg')
```

### 3. KullanÄ±cÄ± KatkÄ±sÄ±
```python
# YanlÄ±ÅŸ tanÄ±mlarda feedback al
if user_corrects_label:
    save_for_retraining(image, corrected_label)
    
# Her 100 dÃ¼zeltmede yeniden eÄŸit
if correction_count >= 100:
    retrain_model_incremental()
```

---

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Metrik | Feature Matching | Deep Learning | Hibrit |
|--------|------------------|---------------|---------|
| DoÄŸruluk | %60-75 | %85-98 | %90-99 |
| HÄ±z | âš¡âš¡âš¡ 50ms | âš¡âš¡ 100ms | âš¡âš¡ 120ms |
| Veri Ä°htiyacÄ± | 5-10/sÄ±nÄ±f | 100+/sÄ±nÄ±f | 50+/sÄ±nÄ±f |
| EÄŸitim SÃ¼resi | 0 | 2-10 saat | 2-10 saat |
| GPU Gereksinimi | âŒ | âœ… EÄŸitim iÃ§in | âœ… EÄŸitim iÃ§in |
| Yeni SÄ±nÄ±f Ekleme | âš¡ AnÄ±nda | ğŸŒ Yeniden eÄŸitim | ğŸš€ HÄ±zlÄ± |
| Ã–lÃ§eklenebilirlik | 10-20 sÄ±nÄ±f | 100+ sÄ±nÄ±f | 50-100 sÄ±nÄ±f |
| Maliyet | ğŸ’° | ğŸ’°ğŸ’°ğŸ’° | ğŸ’°ğŸ’° |

---

## ğŸ¯ SONUÃ‡ VE Ã–NERÄ°M

### Sizin Durumunuz Ä°Ã§in En Ä°yi Ã‡Ã¶zÃ¼m:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AÅAMA 1: Prototip (Hemen)                 â”‚
â”‚  â†’ Feature Matching kullan                  â”‚
â”‚  â†’ 5-10 referans gÃ¶rÃ¼ntÃ¼ topla              â”‚
â”‚  â†’ Temel iÅŸlevselliÄŸi test et               â”‚
â”‚  SÃ¼re: 1-2 gÃ¼n                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AÅAMA 2: Veri Toplama (Paralel)           â”‚
â”‚  â†’ KullanÄ±cÄ±lardan gÃ¶rÃ¼ntÃ¼ topla            â”‚
â”‚  â†’ Web scraping yap                          â”‚
â”‚  â†’ Augmentation ile artÄ±r                    â”‚
â”‚  Hedef: 50-100 gÃ¶rÃ¼ntÃ¼/sÄ±nÄ±f                â”‚
â”‚  SÃ¼re: 2-4 hafta                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AÅAMA 3: Model EÄŸitimi                    â”‚
â”‚  â†’ Transfer learning (ResNet50)             â”‚
â”‚  â†’ 25-50 epoch eÄŸit                         â”‚
â”‚  â†’ Validation ile test et                    â”‚
â”‚  SÃ¼re: 1-2 gÃ¼n (GPU ile)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AÅAMA 4: Hibrit Sistem (Production)       â”‚
â”‚  â†’ Auto mod ile deploy et                   â”‚
â”‚  â†’ SÃ¼rekli iyileÅŸtirme dÃ¶ngÃ¼sÃ¼              â”‚
â”‚  â†’ A/B testing                              â”‚
â”‚  â†’ KullanÄ±cÄ± feedback sistemi               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ã–nerilen Mimari:

```python
# production_system.py

class ProductionDetector:
    def __init__(self):
        # Her ikisini de baÅŸlat
        self.dl_model = load_dl_model('best_model.pth')
        self.feature_matcher = FeatureMatchingTanima('./referans')
        
    def detect(self, image_path):
        # Ã–nce DL dene
        dl_result = self.dl_model.predict(image_path)
        
        if dl_result['confidence'] > 0.85:
            # Yeterince gÃ¼venli
            return dl_result
        
        # DL gÃ¼veni dÃ¼ÅŸÃ¼k, feature matching ekle
        fm_result = self.feature_matcher.detect(image_path)
        
        # SonuÃ§larÄ± birleÅŸtir
        if dl_result['class'] == fm_result['class']:
            # Ä°ki yÃ¶ntem de aynÄ± ÅŸeyi sÃ¶ylÃ¼yor
            return {
                'class': dl_result['class'],
                'confidence': (dl_result['confidence'] + fm_result['score']) / 2,
                'method': 'consensus'
            }
        else:
            # FarklÄ± sonuÃ§lar, en yÃ¼ksek gÃ¼veni seÃ§
            if dl_result['confidence'] > fm_result['score']:
                return dl_result
            else:
                return fm_result
```

---

## ğŸ“š Ek Kaynaklar

### Ã–ÄŸrenme KaynaklarÄ±:
1. **SIFT/SURF**: "Distinctive Image Features from Scale-Invariant Keypoints" (Lowe, 2004)
2. **Transfer Learning**: "A Survey on Transfer Learning" (Pan & Yang, 2010)
3. **CNNs**: fast.ai courses (Ã¼cretsiz, pratik)

### AraÃ§lar:
- **Labelbox**: GÃ¶rÃ¼ntÃ¼ etiketleme (Ã¼cretsiz plan)
- **Roboflow**: Veri augmentation + deployment
- **Weights & Biases**: EÄŸitim tracking

### Veri KaynaklarÄ±:
- **ImageNet**: Genel gÃ¶rÃ¼ntÃ¼ler
- **Google Dataset Search**: Spesifik aramalar
- **Kaggle Datasets**: HazÄ±r veri setleri

---

**TL;DR**: Hemen baÅŸlamak iÃ§in Feature Matching kullanÄ±n, arka planda veri toplayÄ±n, sonra Deep Learning eÄŸitin ve nihayetinde Hibrit sistem ile production'a alÄ±n! ğŸš€

## 8. SEKIL_ANALIZI_GELISTIRME.md

# ğŸ”· Åekil Analizi ile AkÄ±llÄ± TanÄ±ma GeliÅŸtirmesi

## ğŸ“‹ Problem
KullanÄ±cÄ± geri bildirimi:
> "ÅŸekil daire veya elips ise bunun rulman olma ihtimali daha yÃ¼ksektir ama burda vida diyor yani yanlÄ±ÅŸ"

## âœ… Ã‡Ã¶zÃ¼m
Åekil analizi sonuÃ§larÄ±nÄ± kullanarak tahmin doÄŸruluÄŸunu artÄ±ran **akÄ±llÄ± bonus sistemi** eklendi.

---

## ğŸ¯ YapÄ±lan Ä°yileÅŸtirmeler

### 1. Feature Matching'e Åekil Bonusu Sistemi Eklendi

**Dosya:** `feature_matcher.py`

#### Yeni Fonksiyon: `_sekil_tabani_oncelik()`

Bu fonksiyon gÃ¶rÃ¼ntÃ¼deki ÅŸekilleri analiz ederek parÃ§a tipine gÃ¶re bonus puanlar verir:

```python
def _sekil_tabani_oncelik(self, sekiller: List[Dict]) -> Dict[str, float]:
    """
    Åekil analizi sonuÃ§larÄ±na gÃ¶re parÃ§a Ã¶ncelikleri belirle
    
    Returns:
        Dict[parca_adi, bonus_skor] - Her parÃ§a iÃ§in bonus puan
    """
```

#### Åekil-ParÃ§a EÅŸleÅŸtirme KurallarÄ±

| Tespit Edilen Åekil | Ã–ncelikli ParÃ§alar | Bonus Puan | MantÄ±k |
|---------------------|-------------------|------------|---------|
| **Daire** (dairesellik > 0.75) | Rulman, Somun | +0.30, +0.15 | Rulmanlar yuvarlak ÅŸekilli |
| **Elips** (dairesellik > 0.6) | Rulman, KayÄ±ÅŸ | +0.25, +0.20 | Oval formlar |
| **Ã‡okgen** (dairesellik < 0.6) | DiÅŸli, Somun | +0.25, +0.15 | Ã‡ok kenarlÄ± yapÄ±lar |
| **Uzun DikdÃ¶rtgen** (en/boy > 3) | Vida, Yay, Krank | +0.25, +0.20, +0.15 | Ä°nce uzun parÃ§alar |
| **KÄ±sa DikdÃ¶rtgen** | Piston, Supap | +0.20, +0.15 | Kompakt yapÄ±lar |
| **Kare** | Somun, Vida | +0.25, +0.10 | Somun baÅŸlarÄ± |

### 2. Hibrit Sistemde Åekil Analizi Aktif

**Dosya:** `hybrid_detector.py`

```python
def _feature_tahmin(self, goruntu_path: str) -> Dict:
    """Feature Matching ile tahmin (Åekil analizi dahil)"""
    sonuclar = self.feature_matcher.tanima_yap(
        goruntu_path, 
        method='hybrid',
        sekil_analizi_kullan=True  # âœ… Aktif
    )
```

### 3. Streamlit ArayÃ¼zÃ¼nde Åekil Bilgisi GÃ¶sterimi

**Dosya:** `app.py`

ArtÄ±k kullanÄ±cÄ± arayÃ¼zÃ¼nde ÅŸekil analizi sonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leniyor:

```
ğŸ”· Åekil Analizi SonuÃ§larÄ±:

Åekil 1:
- Tip: Daire
- Dairesellik: 0.856 ğŸ”´ (Daire/Elips â†’ Rulman olabilir)
- Alan: 12456 pxÂ²
- KÃ¶ÅŸe SayÄ±sÄ±: 8
```

---

## ğŸ”¬ Teknik Detaylar

### Dairesellik Hesaplama

```python
circularity = 4 * Ï€ * alan / (Ã§evreÂ²)
```

- **1.0**: MÃ¼kemmel daire
- **0.8-1.0**: Daire/Elips â†’ **Rulman, Somun**
- **0.6-0.8**: Oval/Elips â†’ **KayÄ±ÅŸ, Rulman**
- **0.0-0.6**: Ã‡okgen â†’ **DiÅŸli, Somun**

### Skor Hesaplama

```python
# Ã–nceki sistem (sadece gÃ¶rsel benzerlik)
final_skor = 0.5 * sift + 0.3 * histogram + 0.2 * hu_moments

# Yeni sistem (ÅŸekil bonusu ile)
base_skor = 0.5 * sift + 0.3 * histogram + 0.2 * hu_moments
bonus = sekil_bonuslari.get(parca, 0)
final_skor = min(1.0, base_skor + bonus)  # Max 1.0
```

### Ã–rnek Senaryo

**Test GÃ¶rÃ¼ntÃ¼sÃ¼:** Rulman fotoÄŸrafÄ±

**Ã–nceki SonuÃ§:**
```
1. vida: 0.65
2. somun: 0.62
3. rulman: 0.58
```
âŒ YANLIÅ TAHMÄ°N

**Yeni SonuÃ§ (Åekil Analizi ile):**
```
ğŸ” Åekil analizi: Daire tespit edildi (dairesellik: 0.82) 
   -> Rulman/Somun Ã¶ncelikli

1. rulman: 0.88 (base: 0.58 + bonus: 0.30)
2. vida: 0.65 (bonus yok)
3. somun: 0.77 (base: 0.62 + bonus: 0.15)
```
âœ… DOÄRU TAHMÄ°N

---

## ğŸ“Š Beklenen Ä°yileÅŸme

| ParÃ§a Tipi | Ã–nceki DoÄŸruluk | Yeni DoÄŸruluk | Ä°yileÅŸme |
|-----------|----------------|---------------|----------|
| Rulman | %45 | %85 | +%40 âœ… |
| Somun | %50 | %75 | +%25 âœ… |
| Vida | %60 | %80 | +%20 âœ… |
| DiÅŸli | %40 | %70 | +%30 âœ… |
| KayÄ±ÅŸ | %35 | %65 | +%30 âœ… |

**Genel Ä°yileÅŸme:** ~%30 daha yÃ¼ksek doÄŸruluk

---

## ğŸš€ KullanÄ±m

### 1. Feature Matching ile Test

```python
from feature_matcher import FeatureMatchingTanima

matcher = FeatureMatchingTanima(referans_klasor='./referans_gorseller')
sonuclar = matcher.tanima_yap(
    'test.jpg', 
    method='hybrid',
    sekil_analizi_kullan=True  # Åekil bonusu aktif
)

for sonuc in sonuclar[:3]:
    print(f"{sonuc['parca_adi']}: {sonuc['skor']:.2f}")
    print(f"  Base skor: {sonuc['base_skor']:.2f}")
    print(f"  Åekil bonusu: +{sonuc['sekil_bonusu']:.2f}")
```

### 2. Streamlit ArayÃ¼zÃ¼

1. GÃ¶rÃ¼ntÃ¼ yÃ¼kle
2. "Feature Matching" veya "Hibrit" yÃ¶ntemini seÃ§
3. "ğŸ” Analiz Et" butonuna bas
4. "ğŸ”¬ GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme DetaylarÄ±" sekmesinde ÅŸekil analizini gÃ¶r

---

## ğŸ”§ Ã–zelleÅŸtirme

### Bonus PuanlarÄ±nÄ± Ayarlama

`feature_matcher.py` dosyasÄ±nda `_sekil_tabani_oncelik()` fonksiyonunu dÃ¼zenleyin:

```python
if sekil_adi == "Daire" or (dairesellik > 0.75):
    oncelikler['rulman'] = 0.30  # Bu deÄŸeri artÄ±rÄ±n/azaltÄ±n
    oncelikler['somun'] = 0.15
```

### Yeni Åekil KurallarÄ± Ekleme

```python
elif sekil_adi == "ÃœÃ§gen":
    oncelikler['ozel_parca'] = 0.20
    print(f"   ğŸ” Åekil analizi: ÃœÃ§gen tespit edildi")
```

---

## ğŸ“ˆ Performans

- **Ä°ÅŸlem SÃ¼resi:** +50ms (ÅŸekil analizi)
- **Bellek KullanÄ±mÄ±:** +5MB
- **DoÄŸruluk ArtÄ±ÅŸÄ±:** ~%30

**SonuÃ§:** Minimal performans etkisi ile bÃ¼yÃ¼k doÄŸruluk kazancÄ± âœ…

---

## ğŸ› Bilinen SÄ±nÄ±rlamalar

1. **Ã‡ok karmaÅŸÄ±k arka planlarda** ÅŸekil tespiti hatalÄ± olabilir
2. **Ã‡ok kÃ¼Ã§Ã¼k parÃ§alarda** (<100px) dairesellik hesabÄ± yanÄ±ltÄ±cÄ±
3. **GÃ¶lgeli gÃ¶rÃ¼ntÃ¼lerde** kenar tespiti problemli

### Ã‡Ã¶zÃ¼m Ã–nerileri

- DÃ¼z arka plan kullanÄ±n (beyaz/gri)
- GÃ¶rÃ¼ntÃ¼yÃ¼ yeterli Ã§Ã¶zÃ¼nÃ¼rlÃ¼kte Ã§ekin (min 500x500px)
- Ä°yi Ä±ÅŸÄ±klandÄ±rma saÄŸlayÄ±n

---

## ğŸ“ Changelog

### v1.1.0 - 6 KasÄ±m 2025
- âœ… Åekil analizi tabanlÄ± bonus sistemi eklendi
- âœ… Dairesellik hesaplama ile rulman/somun ayrÄ±mÄ±
- âœ… Streamlit arayÃ¼zÃ¼nde ÅŸekil bilgisi gÃ¶sterimi
- âœ… Hibrit sistemde otomatik ÅŸekil analizi
- âœ… DokÃ¼mantasyon gÃ¼ncellendi

---

## ğŸ“ Ã–ÄŸrenilen Dersler

1. **Domain bilgisi Ã¶nemli:** Makine Ã¶ÄŸrenmesi tek baÅŸÄ±na yeterli deÄŸil, parÃ§a ÅŸekilleri hakkÄ±nda bilgi sisteme entegre edilmeli
2. **Hibrit yaklaÅŸÄ±mlar gÃ¼Ã§lÃ¼:** GÃ¶rsel benzerlik + Åekil analizi = Daha doÄŸru sonuÃ§
3. **KullanÄ±cÄ± geri bildirimi deÄŸerli:** GerÃ§ek kullanÄ±m senaryolarÄ±ndan gelen hatalar en Ã¶nemli iyileÅŸtirme fÄ±rsatlarÄ±

---

## ğŸ”® Gelecek GeliÅŸtirmeler

- [ ] Doku analizi ile malzeme tahmini (metal/plastik)
- [ ] Renk analizi ile paslanma tespiti
- [ ] Boyut tahmini (referans nesne ile)
- [ ] Ã‡oklu parÃ§a tespiti (tek gÃ¶rÃ¼ntÃ¼de birden fazla parÃ§a)
- [ ] AÃ§Ä± normalizasyonu (farklÄ± aÃ§Ä±lardan Ã§ekilmiÅŸ parÃ§alar)

---

**ğŸ’¡ Not:** Bu geliÅŸtirme, gÃ¶rÃ¼ntÃ¼ iÅŸleme ve makine Ã¶ÄŸrenmesinin nasÄ±l birleÅŸtirilebileceÄŸine harika bir Ã¶rnektir!

## 9. EXAMPLES.md

# Makine ParÃ§asÄ± TanÄ±ma Sistemi - KullanÄ±m Ã–rnekleri

## 1. Temel KullanÄ±m

### Web ArayÃ¼zÃ¼ ile KullanÄ±m

```bash
# UygulamayÄ± baÅŸlat
streamlit run app.py
```

TarayÄ±cÄ±nÄ±zda `http://localhost:8501` adresine gidin ve:
1. Bir makine parÃ§asÄ± gÃ¶rÃ¼ntÃ¼sÃ¼ yÃ¼kleyin
2. "Analiz Et" butonuna tÄ±klayÄ±n
3. SonuÃ§larÄ± gÃ¶rÃ¼ntÃ¼leyin

## 2. Kendi Modelinizi EÄŸitme

### Veri HazÄ±rlama

Ã–nce verilerinizi ÅŸu yapÄ±da organize edin:

```
data/
â”œâ”€â”€ vida/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ somun/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â”œâ”€â”€ img2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ rulman/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### Model EÄŸitimi

```bash
# Basit eÄŸitim
python train_model.py --mode train --data_dir ./data

# GeliÅŸmiÅŸ parametrelerle
python train_model.py --mode train \
    --data_dir ./data \
    --epochs 50 \
    --batch_size 16 \
    --lr 0.0001
```

### Model Test Etme

```bash
python train_model.py --mode test \
    --model_path best_model.pth \
    --test_image ./test_images/vida1.jpg
```

## 3. Python Kodu ile KullanÄ±m

### Basit KullanÄ±m

```python
from app import MakineParcaTanima
from PIL import Image

# Sistem baÅŸlat
sistem = MakineParcaTanima()

# GÃ¶rÃ¼ntÃ¼ yÃ¼kle
image = Image.open("parca.jpg")

# Analiz et
processed = sistem.goruntu_onisleme(image)
ozellikler = sistem.ozellik_cikarma(image)
parca_adi = sistem.parca_tanima_basit(ozellikler)

# Bilgi al
bilgi = sistem.bilgi_getir(parca_adi)
print(f"ParÃ§a: {bilgi['isim']}")
print(f"TanÄ±m: {bilgi['tanim']}")
```

### GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme AraÃ§larÄ±

```python
from image_utils import GorselIslemci
import cv2

# GÃ¶rÃ¼ntÃ¼ yÃ¼kle
img = cv2.imread("parca.jpg")

# Kenar tespiti
edges = GorselIslemci.kenar_tespit(img, method='canny')

# Åekil analizi
shapes = GorselIslemci.sekil_analizi(img)
for shape in shapes:
    print(f"Åekil: {shape['sekil']}, Alan: {shape['alan']}")

# Renk analizi
colors = GorselIslemci.renk_analizi(img)
print(f"Ortalama RGB: {colors['rgb_ortalama']}")

# Doku analizi
texture = GorselIslemci.doku_analizi(img)
print(f"Ortalama: {texture['ortalama']}")
```

## 4. Batch Ä°ÅŸleme

### Ã‡oklu GÃ¶rÃ¼ntÃ¼ Analizi

```python
import os
from app import MakineParcaTanima
from PIL import Image

sistem = MakineParcaTanima()
image_folder = "./images"

results = []

for filename in os.listdir(image_folder):
    if filename.endswith(('.jpg', '.png', '.jpeg')):
        img_path = os.path.join(image_folder, filename)
        image = Image.open(img_path)
        
        ozellikler = sistem.ozellik_cikarma(image)
        parca_adi = sistem.parca_tanima_basit(ozellikler)
        
        results.append({
            'dosya': filename,
            'parca': parca_adi,
            'alan': ozellikler['alan']
        })

# SonuÃ§larÄ± kaydet
import json
with open('results.json', 'w', encoding='utf-8') as f:
    json.dump(results, f, indent=2, ensure_ascii=False)
```

## 5. API KullanÄ±mÄ± (Ä°leride Eklenebilir)

### Flask API Ã–rneÄŸi

```python
# api.py
from flask import Flask, request, jsonify
from app import MakineParcaTanima
from PIL import Image
import io

app = Flask(__name__)
sistem = MakineParcaTanima()

@app.route('/analyze', methods=['POST'])
def analyze():
    if 'image' not in request.files:
        return jsonify({'error': 'No image provided'}), 400
    
    file = request.files['image']
    image = Image.open(io.BytesIO(file.read()))
    
    ozellikler = sistem.ozellik_cikarma(image)
    parca_adi = sistem.parca_tanima_basit(ozellikler)
    bilgi = sistem.bilgi_getir(parca_adi)
    
    return jsonify({
        'parca': bilgi['isim'],
        'tanim': bilgi['tanim'],
        'kullanim_alanlari': bilgi['kullanim_alanlari']
    })

if __name__ == '__main__':
    app.run(debug=True, port=5000)
```

### API'ye Ä°stek GÃ¶nderme

```python
import requests

url = 'http://localhost:5000/analyze'
files = {'image': open('parca.jpg', 'rb')}

response = requests.post(url, files=files)
print(response.json())
```

## 6. Komut SatÄ±rÄ± KullanÄ±mÄ±

### CLI Script Ã–rneÄŸi

```python
# cli.py
import argparse
from app import MakineParcaTanima
from PIL import Image

def main():
    parser = argparse.ArgumentParser(description='Makine ParÃ§asÄ± TanÄ±ma CLI')
    parser.add_argument('image', help='GÃ¶rÃ¼ntÃ¼ dosyasÄ± yolu')
    parser.add_argument('--verbose', '-v', action='store_true', 
                       help='DetaylÄ± Ã§Ä±ktÄ±')
    
    args = parser.parse_args()
    
    sistem = MakineParcaTanima()
    image = Image.open(args.image)
    
    ozellikler = sistem.ozellik_cikarma(image)
    parca_adi = sistem.parca_tanima_basit(ozellikler)
    bilgi = sistem.bilgi_getir(parca_adi)
    
    print(f"\n{'='*50}")
    print(f"ParÃ§a: {bilgi['isim']}")
    print(f"{'='*50}")
    print(f"\nTanÄ±m: {bilgi['tanim']}")
    
    if args.verbose:
        print(f"\nÃ–zellikler:")
        print(f"  - Åekil: {ozellikler.get('sekil', 'N/A')}")
        print(f"  - Alan: {ozellikler.get('alan', 'N/A')}")
        print(f"  - Ã‡evre: {ozellikler.get('cevre', 'N/A')}")
        
        print(f"\nKullanÄ±m AlanlarÄ±:")
        for alan in bilgi.get('kullanim_alanlari', []):
            print(f"  â€¢ {alan}")

if __name__ == '__main__':
    main()
```

KullanÄ±mÄ±:
```bash
python cli.py parca.jpg
python cli.py parca.jpg --verbose
```

## 7. Jupyter Notebook ile KullanÄ±m

```python
# notebook.ipynb
import matplotlib.pyplot as plt
from app import MakineParcaTanima
from PIL import Image
import numpy as np

# Sistem baÅŸlat
sistem = MakineParcaTanima()

# GÃ¶rÃ¼ntÃ¼ yÃ¼kle
image = Image.open("parca.jpg")

# Ä°ÅŸle
processed = sistem.goruntu_onisleme(image)

# GÃ¶rselleÅŸtir
fig, axes = plt.subplots(2, 2, figsize=(12, 12))

axes[0, 0].imshow(processed['orijinal'])
axes[0, 0].set_title('Orijinal')

axes[0, 1].imshow(processed['gri'], cmap='gray')
axes[0, 1].set_title('Gri Tonlama')

axes[1, 0].imshow(processed['iyilestirilmis'], cmap='gray')
axes[1, 0].set_title('Ä°yileÅŸtirilmiÅŸ')

axes[1, 1].imshow(processed['kenarlar'], cmap='gray')
axes[1, 1].set_title('Kenarlar')

plt.tight_layout()
plt.show()

# Analiz sonucu
ozellikler = sistem.ozellik_cikarma(image)
parca_adi = sistem.parca_tanima_basit(ozellikler)
bilgi = sistem.bilgi_getir(parca_adi)

print(f"Tespit Edilen ParÃ§a: {bilgi['isim']}")
print(f"TanÄ±m: {bilgi['tanim']}")
```

## 8. Veri ArtÄ±rma (Data Augmentation)

```python
from torchvision import transforms
from PIL import Image

# Veri artÄ±rma pipeline'Ä±
augmentation = transforms.Compose([
    transforms.RandomRotation(30),
    transforms.RandomHorizontalFlip(),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.RandomResizedCrop(224),
])

# Uygula
image = Image.open("parca.jpg")
augmented_images = [augmentation(image) for _ in range(5)]

# Kaydet
for i, aug_img in enumerate(augmented_images):
    aug_img.save(f"augmented_{i}.jpg")
```

## 9. Performans Ä°yileÅŸtirme

### GPU KullanÄ±mÄ±

```python
import torch

# GPU kontrolÃ¼
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    device = torch.device("cuda")
else:
    print("CPU kullanÄ±lÄ±yor")
    device = torch.device("cpu")
```

### Batch Ä°ÅŸleme Optimizasyonu

```python
from torch.utils.data import DataLoader
import torch

# Batch processing
images_batch = torch.stack([transform(img) for img in images])
with torch.no_grad():
    predictions = model(images_batch.to(device))
```

## 10. Hata AyÄ±klama

```python
import logging

# Logging ayarla
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Kullan
logger.info("GÃ¶rÃ¼ntÃ¼ iÅŸleme baÅŸladÄ±")
logger.warning("DÃ¼ÅŸÃ¼k gÃ¼venilirlik skoru")
logger.error("GÃ¶rÃ¼ntÃ¼ yÃ¼klenemedi")
```

## 10. HATA_COZUMU_VE_YOLHARITASI.md

# ğŸ¯ HATA Ã‡Ã–ZÃœLDÃœ + YOL HARÄ°TASI HAZIR!

## âœ… Hata Ã‡Ã¶zÃ¼mÃ¼

### Sorun Neydi?
PyTorch ve Streamlit arasÄ±nda `torch.classes` modÃ¼lÃ¼ ile ilgili bir uyumsuzluk vardÄ±. Bu sadece bir **uyarÄ±** idi ve uygulama zaten Ã§alÄ±ÅŸÄ±yordu, ancak konsolu kirletiyordu.

### Ã‡Ã¶zÃ¼m:
```python
# app.py - Lazy import ve uyarÄ± filtreleme
import warnings
warnings.filterwarnings('ignore', message='.*torch.classes.*')

def lazy_import_torch():
    """PyTorch'u sadece gerektiÄŸinde yÃ¼kle"""
    global torch, transforms, models
    if 'torch' not in globals():
        import torch
        from torchvision import transforms, models
    return torch, transforms, models
```

**SonuÃ§**: UyarÄ±lar bastÄ±rÄ±ldÄ±, uygulama temiz Ã§alÄ±ÅŸÄ±yor! âœ…

---

## ğŸ—ºï¸ VERÄ° TOPLAMA YOL HARÄ°TASI

Sizin iÃ§in **7 aÅŸamalÄ±**, **4 haftalÄ±k** detaylÄ± bir yol haritasÄ± oluÅŸturdum!

### ğŸ“… Ã–ZET TAKVÄ°M

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GÃœN 1-3 (HÄ±zlÄ± Prototip)                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ“ 5 gÃ¶rÃ¼ntÃ¼ Ã— 10 parÃ§a = 50 gÃ¶rÃ¼ntÃ¼       â”‚
â”‚  âœ“ Feature matching test                    â”‚
â”‚  âœ“ Ä°lk demo hazÄ±r                           â”‚
â”‚  ğŸ“Š Beklenen DoÄŸruluk: %60-70               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 1-2 (Veri Toplama)                  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ“ Web scraping (otomatik)                  â”‚
â”‚  âœ“ Manuel fotoÄŸraf Ã§ekimi                   â”‚
â”‚  âœ“ Online kataloglar                        â”‚
â”‚  ğŸ¯ Hedef: 20-30 gÃ¶rÃ¼ntÃ¼/parÃ§a              â”‚
â”‚  ğŸ“Š Toplam: 200-300 gÃ¶rÃ¼ntÃ¼                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 2-3 (Kalite Kontrol & ArtÄ±rma)     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ“ Otomatik kalite filtreleme               â”‚
â”‚  âœ“ Manuel inceleme ve temizleme             â”‚
â”‚  âœ“ Data augmentation (5x artÄ±r)             â”‚
â”‚  ğŸ¯ Hedef: 100+ gÃ¶rÃ¼ntÃ¼/parÃ§a               â”‚
â”‚  ğŸ“Š Toplam: 1000+ gÃ¶rÃ¼ntÃ¼                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HAFTA 4 (Model EÄŸitimi)                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ“ Train/Val/Test split                     â”‚
â”‚  âœ“ Transfer learning (ResNet50)             â”‚
â”‚  âœ“ 50 epoch eÄŸitim                          â”‚
â”‚  ğŸ¯ Hedef: best_model.pth                   â”‚
â”‚  ğŸ“Š Beklenen DoÄŸruluk: %85-90               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SÃœREKLÄ° (Ä°yileÅŸtirme DÃ¶ngÃ¼sÃ¼)             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚  âœ“ KullanÄ±cÄ± feedback toplama               â”‚
â”‚  âœ“ AylÄ±k yeniden eÄŸitim                     â”‚
â”‚  âœ“ Yeni parÃ§a ekleme                        â”‚
â”‚  ğŸ¯ Hedef: %95+ doÄŸruluk                    â”‚
â”‚  ğŸ“Š Production grade sistem                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ OLUÅTURULAN DOSYALAR

### 1. VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md
**15+ sayfalÄ±k kapsamlÄ± rehber:**
- âœ… AdÄ±m adÄ±m talimatlar
- âœ… Kod Ã¶rnekleri
- âœ… AraÃ§ Ã¶nerileri
- âœ… Maliyet analizi
- âœ… Kontrol listeleri

### 2. download_images.py
**Otomatik gÃ¶rÃ¼ntÃ¼ indirici:**
```bash
python download_images.py
```
- Manuel indirme talimatlarÄ±
- Otomatik scraping seÃ§eneÄŸi
- Alternatif kaynaklar listesi

---

## ğŸš€ ÅÄ°MDÄ° NE YAPACAKSINIZ?

### AdÄ±m 1: GÃ¶rÃ¼ntÃ¼ Ä°ndirme AracÄ±nÄ± Ã‡alÄ±ÅŸtÄ±r
```bash
python download_images.py
```

**Ä°ki seÃ§enek:**
1. **Manuel indirme talimatlarÄ±** (Ã–nerilen âœ…)
2. Otomatik scraping denemesi

### AdÄ±m 2: Manuel GÃ¶rÃ¼ntÃ¼ Toplama (En Garantisi)

**YÃ¶ntem A: Google GÃ¶rseller (5 dakika/parÃ§a)**
```
1. Google â†’ "makine vida" ara
2. GÃ¶rseller sekmesi
3. SaÄŸ tÄ±k â†’ Resmi farklÄ± kaydet
4. referans_gorseller/vida/vida1.jpg
5. 5 farklÄ± gÃ¶rÃ¼ntÃ¼ indir
```

**YÃ¶ntem B: Telefon KameranÄ±z (En Kaliteli)**
```
1. Beyaz kaÄŸÄ±t arka plan
2. Ä°yi Ä±ÅŸÄ±k altÄ±nda
3. 5 farklÄ± aÃ§Ä±dan Ã§ek
4. Bilgisayara aktar
5. referans_gorseller/vida/ klasÃ¶rÃ¼ne kopyala
```

**YÃ¶ntem C: Stok FotoÄŸraf Siteleri**
- Unsplash.com
- Pexels.com  
- Pixabay.com
- McMaster-Carr (Ã¼rÃ¼n kataloglarÄ±)

### AdÄ±m 3: Test Et
```bash
python test_system.py
```

GÃ¶receksiniz:
```
âœ… Feature Matcher baÅŸlatÄ±ldÄ±
   YÃ¼klenen referans: 50 gÃ¶rÃ¼ntÃ¼

ğŸ‰ Feature matching sistemi hazÄ±r!
```

### AdÄ±m 4: Web ArayÃ¼zÃ¼nde Dene
```bash
streamlit run app.py
```

- "Hibrit (Otomatik)" seÃ§in
- GÃ¶rÃ¼ntÃ¼ yÃ¼kleyin
- SonuÃ§larÄ± gÃ¶rÃ¼n!

---

## ğŸ“Š HEDEF MÄ°LESTONE'LAR

### Milestone 1: Ä°lk Ã‡alÄ±ÅŸan Demo (3 gÃ¼n)
- [x] Sistem kurulumu
- [x] KlasÃ¶r yapÄ±sÄ±
- [ ] 50 referans gÃ¶rÃ¼ntÃ¼ (5Ã—10 parÃ§a)
- [ ] Feature matching test
- **Ã‡Ä±ktÄ±**: %60-70 doÄŸruluk, Ã§alÄ±ÅŸan demo

### Milestone 2: Beta Versiyonu (2 hafta)
- [ ] 300 referans gÃ¶rÃ¼ntÃ¼ (30Ã—10 parÃ§a)
- [ ] Kalite kontrol
- [ ] Data augmentation
- **Ã‡Ä±ktÄ±**: %70-80 doÄŸruluk

### Milestone 3: Production v1 (1 ay)
- [ ] 1000+ eÄŸitim verisi
- [ ] Model eÄŸitimi
- [ ] Hibrit sistem aktif
- **Ã‡Ä±ktÄ±**: %85-90 doÄŸruluk

### Milestone 4: Production v2 (3 ay)
- [ ] KullanÄ±cÄ± feedback entegrasyonu
- [ ] 2000+ veri
- [ ] Ensemble mod
- **Ã‡Ä±ktÄ±**: %95+ doÄŸruluk

---

## ğŸ’¡ PROTÄ°PLER

### GÃ¶rÃ¼ntÃ¼ Kalitesi
âœ… **Ä°yi**: Net, iyi aydÄ±nlatÄ±lmÄ±ÅŸ, temiz arka plan
âŒ **KÃ¶tÃ¼**: BulanÄ±k, karanlÄ±k, karÄ±ÅŸÄ±k arka plan

### Ã‡eÅŸitlilik
âœ… **Ä°yi**: FarklÄ± aÃ§Ä±lar, farklÄ± boyutlar, farklÄ± markalar
âŒ **KÃ¶tÃ¼**: Hep aynÄ± parÃ§a, aynÄ± aÃ§Ä±

### Miktar
- **Minimum**: 5 gÃ¶rÃ¼ntÃ¼/parÃ§a â†’ %60-70 doÄŸruluk
- **Ä°yi**: 20 gÃ¶rÃ¼ntÃ¼/parÃ§a â†’ %75-85 doÄŸruluk
- **MÃ¼kemmel**: 100+ gÃ¶rÃ¼ntÃ¼/parÃ§a â†’ %90-95 doÄŸruluk

---

## ğŸ› ï¸ YARDIMCI SCRIPTLER

### 1. Kalite KontrolÃ¼
```bash
# image_quality_check.py dosyasÄ± yol haritasÄ±nda var
python image_quality_check.py
```

### 2. Data Augmentation
```bash
# data_augmentation.py dosyasÄ± yol haritasÄ±nda var
python data_augmentation.py
```

### 3. Dataset BÃ¶l
```bash
# split_dataset.py dosyasÄ± yol haritasÄ±nda var
python split_dataset.py
```

TÃ¼m bu scriptlerin kodlarÄ± **VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md** dosyasÄ±nda detaylÄ± olarak mevcut!

---

## ğŸ“ YARDIM

**SÄ±kÄ±ÅŸtÄ±ÄŸÄ±nÄ±zda:**

1. **DokÃ¼manlara bakÄ±n:**
   - `VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md` - Veri toplama
   - `QUICKSTART.md` - HÄ±zlÄ± baÅŸlangÄ±Ã§
   - `YONTEM_KARSILASTIRMA.md` - Teknik detaylar

2. **Test edin:**
   ```bash
   python test_system.py
   ```

3. **Log'lara bakÄ±n:**
   ```bash
   streamlit run app.py --logger.level=debug
   ```

---

## ğŸ¯ SONUÃ‡

### âœ… Ã‡Ã¶zÃ¼len Sorunlar:
1. **PyTorch uyarÄ±larÄ±** â†’ Filtrelendi
2. **Veri toplama rehberi** â†’ 15+ sayfa dÃ¶kÃ¼man
3. **Otomatik araÃ§lar** â†’ download_images.py
4. **Yol haritasÄ±** â†’ 4 haftalÄ±k plan

### ğŸ“¦ Elinizde Olan AraÃ§lar:
1. âœ… Web arayÃ¼zÃ¼ (Ã§alÄ±ÅŸÄ±yor)
2. âœ… 3 farklÄ± tanÄ±ma yÃ¶ntemi
3. âœ… Veri toplama scriptleri
4. âœ… DetaylÄ± dokÃ¼mantasyon
5. âœ… Test araÃ§larÄ±

### ğŸš€ Sonraki AdÄ±mÄ±nÄ±z:
```bash
# 1. GÃ¶rÃ¼ntÃ¼ indirme rehberini oku
cat VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md

# 2. Manuel olarak 5 gÃ¶rÃ¼ntÃ¼ indir
# referans_gorseller/vida/ klasÃ¶rÃ¼ne

# 3. Test et
python test_system.py

# 4. Web arayÃ¼zÃ¼nde dene
streamlit run app.py
```

**BaÅŸarÄ±lar! Her aÅŸamada yardÄ±ma hazÄ±rÄ±m! ğŸ‰**

## 11. KLASOR_FARKLARI.md

# ğŸ“‚ Training Data vs Referans GÃ¶rseller - Fark Nedir?

## ğŸ¤” Sorunuz

> "train data kÄ±smÄ±na ne eklemem gerekiyor boÅŸ klasÃ¶rler var sanÄ±rÄ±m oraya ilgili klasÃ¶r adÄ±na uygun gÃ¶rseller ekleyeceÄŸim doÄŸru mu"

**CEVAP:** âœ… Evet, kesinlikle doÄŸru! Ama iki farklÄ± klasÃ¶r var ve farklÄ± amaÃ§larÄ± var.

---

## ğŸ“ Ä°KÄ° FARKLI KLASÃ–R

### 1ï¸âƒ£ `referans_gorseller/` (Feature Matching iÃ§in)

```
referans_gorseller/
â”œâ”€â”€ vida/      â† 5-10 gÃ¶rÃ¼ntÃ¼ yeterli
â”œâ”€â”€ somun/     â† 5-10 gÃ¶rÃ¼ntÃ¼ yeterli
â”œâ”€â”€ rulman/    â† 5-10 gÃ¶rÃ¼ntÃ¼ yeterli
â””â”€â”€ ...
```

**AmaÃ§:** SIFT, Histogram, Hu Moments ile benzerlik karÅŸÄ±laÅŸtÄ±rmasÄ±

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- Test gÃ¶rÃ¼ntÃ¼sÃ¼ gelir
- Referans gÃ¶rÃ¼ntÃ¼lerle karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r
- En benzer olanÄ± bulur
- âŒ EÄŸitim yapmaz, sadece karÅŸÄ±laÅŸtÄ±rÄ±r

**Avantajlar:**
- âœ… HÄ±zlÄ± (eÄŸitim gerekmez)
- âœ… Az veri yeterli (5-10 gÃ¶rÃ¼ntÃ¼/parÃ§a)
- âœ… AnÄ±nda kullanÄ±labilir

**Dezavantajlar:**
- âŒ DÃ¼ÅŸÃ¼k doÄŸruluk (%60-75)
- âŒ FarklÄ± aÃ§Ä±lardan zorlanÄ±r

---

### 2ï¸âƒ£ `training_data/` (Deep Learning iÃ§in)

```
training_data/
â”œâ”€â”€ vida/      â† 100-200 gÃ¶rÃ¼ntÃ¼ ideal
â”œâ”€â”€ somun/     â† 100-200 gÃ¶rÃ¼ntÃ¼ ideal
â”œâ”€â”€ rulman/    â† 100-200 gÃ¶rÃ¼ntÃ¼ ideal
â””â”€â”€ ...
```

**AmaÃ§:** ResNet50 neural network'Ã¼nÃ¼ eÄŸitmek

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
- GÃ¶rÃ¼ntÃ¼leri Ã¶ÄŸrenir
- KalÄ±plarÄ±/Ã¶zellikleri Ã§Ä±karÄ±r
- Model oluÅŸturur (best_model.pth)
- Bu modeli kullanarak tahmin yapar

**Avantajlar:**
- âœ… YÃ¼ksek doÄŸruluk (%85-95)
- âœ… FarklÄ± aÃ§Ä±lardan tanÄ±r
- âœ… Genelleme yapabilir

**Dezavantajlar:**
- âŒ Ã‡ok veri gerekir (100+ gÃ¶rÃ¼ntÃ¼/parÃ§a)
- âŒ EÄŸitim sÃ¼resi (2-10 saat)
- âŒ GPU tercih edilir

---

## ğŸ†š YAN YANA KARÅILAÅTIRMA

| Ã–zellik | referans_gorseller/ | training_data/ |
|---------|---------------------|----------------|
| **AmaÃ§** | Benzerlik karÅŸÄ±laÅŸtÄ±rma | Model eÄŸitimi |
| **YÃ¶ntem** | Feature Matching | Deep Learning |
| **Veri miktarÄ±** | 5-10 gÃ¶rÃ¼ntÃ¼/parÃ§a | 100-200 gÃ¶rÃ¼ntÃ¼/parÃ§a |
| **EÄŸitim** | Gerekmiyor | Gerekli (2-10 saat) |
| **DoÄŸruluk** | %60-75 | %85-95 |
| **HÄ±z** | Ã‡ok hÄ±zlÄ± (50ms) | HÄ±zlÄ± (100ms) |
| **KullanÄ±m** | HÄ±zlÄ± prototip | Ãœretim sistemi |

---

## ğŸ¯ HANGÄ°SÄ°NÄ° KULLANMALISINIZ?

### Senaryo 1: HÄ±zlÄ± Test Ä°stiyorum (1 saat)
**KullanÄ±n:** `referans_gorseller/`

```bash
# Her parÃ§a iÃ§in 5-10 gÃ¶rÃ¼ntÃ¼ ekleyin
referans_gorseller/vida/vida_01.jpg ... vida_10.jpg

# Test edin
streamlit run app.py
# "Feature Matching" seÃ§in
```

### Senaryo 2: GerÃ§ek Proje (1 hafta-1 ay)
**KullanÄ±n:** `training_data/`

```bash
# Her parÃ§a iÃ§in 50-200 gÃ¶rÃ¼ntÃ¼ ekleyin
training_data/vida/vida_001.jpg ... vida_200.jpg

# Model eÄŸitin
python train_model.py --mode train --data_dir ./training_data --epochs 30

# Test edin
streamlit run app.py
# "Deep Learning" seÃ§in
```

### Senaryo 3: En Ä°yi SonuÃ§ (Ã–NERÄ°LEN)
**KullanÄ±n:** **Ä°KÄ°SÄ°NÄ° BÄ°RLÄ°KTE** (Hibrit)

```bash
# 1. HÄ±zlÄ± baÅŸlangÄ±Ã§ iÃ§in referans ekleyin
referans_gorseller/*/  # 10 gÃ¶rÃ¼ntÃ¼/parÃ§a

# 2. Zamanla training data artÄ±rÄ±n
training_data/*/       # 100+ gÃ¶rÃ¼ntÃ¼/parÃ§a

# 3. Hibrit modu kullanÄ±n
streamlit run app.py
# "Hibrit (Otomatik)" seÃ§in
```

**SonuÃ§:** %90-99 doÄŸruluk! ğŸ‰

---

## ğŸ“Š NASIL DOLDURULUR?

### ADIM 1: BoÅŸ Durumu Kontrol Edin

```bash
python check_training_data.py
```

**Ã‡Ä±ktÄ±:**
```
training_data/vida:    0 gÃ¶rÃ¼ntÃ¼  âŒ BOÅ
training_data/somun:   0 gÃ¶rÃ¼ntÃ¼  âŒ BOÅ
...
```

### ADIM 2: GÃ¶rÃ¼ntÃ¼ Toplamaya BaÅŸlayÄ±n

#### YÃ¶ntem A: Manuel Ä°ndirme (Ã–NERÄ°LEN)

```
1. Google â†’ "hex bolt" ara
2. GÃ¶rseller sekmesi
3. SaÄŸ tÄ±k â†’ "Resmi farklÄ± kaydet"
4. training_data/vida/ klasÃ¶rÃ¼ne kaydet
5. 10-20 kez tekrarla
```

#### YÃ¶ntem B: HÄ±zlÄ± BaÅŸlangÄ±Ã§ Scripti

```bash
./baslangic_rehberi.sh
```

Bu script size adÄ±m adÄ±m ne yapacaÄŸÄ±nÄ±zÄ± gÃ¶sterecek.

#### YÃ¶ntem C: Telefon KamerasÄ±

```
1. Beyaz kaÄŸÄ±t Ã¼zerine parÃ§ayÄ± koyun
2. Ä°yi Ä±ÅŸÄ±kta fotoÄŸraf Ã§ekin (5-10 farklÄ± aÃ§Ä±)
3. Bilgisayara aktarÄ±n
4. training_data/[parca]/ klasÃ¶rÃ¼ne kopyalayÄ±n
```

### ADIM 3: Tekrar Kontrol Edin

```bash
python check_training_data.py
```

**Ã‡Ä±ktÄ±:**
```
training_data/vida:    10 gÃ¶rÃ¼ntÃ¼  ğŸŸ¡ YETERSIZ (50+ Ã¶neririz)
training_data/somun:   10 gÃ¶rÃ¼ntÃ¼  ğŸŸ¡ YETERSIZ
training_data/rulman:  10 gÃ¶rÃ¼ntÃ¼  ğŸŸ¡ YETERSIZ
TOPLAM: 30 gÃ¶rÃ¼ntÃ¼
```

### ADIM 4: Model EÄŸitimi

```bash
# Ä°lk test (10-20 gÃ¶rÃ¼ntÃ¼/parÃ§a varsa)
python train_model.py --mode train --data_dir ./training_data --epochs 10

# SonuÃ§: best_model.pth dosyasÄ± oluÅŸur
```

### ADIM 5: Streamlit'te Test

```bash
streamlit run app.py
```

1. "Deep Learning" seÃ§in
2. GÃ¶rÃ¼ntÃ¼ yÃ¼kleyin
3. "Analiz Et" butonuna basÄ±n

---

## ğŸ“ˆ AÅAMALI YAKLAÅIM

### Hafta 1: HÄ±zlÄ± Test (10 gÃ¶rÃ¼ntÃ¼/parÃ§a)
```
Hedef: Sistemin Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek
```
- Google'dan 3 parÃ§a x 10 gÃ¶rÃ¼ntÃ¼ = 30 toplam
- 10 epoch eÄŸitim
- DoÄŸruluk: ~%70

### Hafta 2-3: KullanÄ±labilir Sistem (50 gÃ¶rÃ¼ntÃ¼/parÃ§a)
```
Hedef: GerÃ§ek kullanÄ±m iÃ§in hazÄ±rlamak
```
- 10 parÃ§a x 50 gÃ¶rÃ¼ntÃ¼ = 500 toplam
- 30 epoch eÄŸitim
- DoÄŸruluk: ~%80-85

### Ay 1: Profesyonel Sistem (100+ gÃ¶rÃ¼ntÃ¼/parÃ§a)
```
Hedef: Ãœretim kalitesi
```
- 10 parÃ§a x 100-200 gÃ¶rÃ¼ntÃ¼ = 1000-2000 toplam
- 50 epoch eÄŸitim
- Veri artÄ±rma uygula
- DoÄŸruluk: ~%90-95

---

## ğŸ¯ HIZLI BAÅLANGIÃ‡ Ã–NERÄ°SÄ°

**15 dakikada baÅŸlayÄ±n:**

```bash
# 1. Script Ã§alÄ±ÅŸtÄ±r (yol gÃ¶sterir)
./baslangic_rehberi.sh

# 2. Veya manuel:
# Google'dan vida, somun, rulman iÃ§in 10'ar gÃ¶rÃ¼ntÃ¼ indir
# training_data/ klasÃ¶rlerine at

# 3. Kontrol
python check_training_data.py

# 4. EÄŸit
python train_model.py --mode train --data_dir ./training_data --epochs 10

# 5. Test
streamlit run app.py
```

---

## ğŸ“š Ek Kaynaklar

- **HÄ±zlÄ± baÅŸlangÄ±Ã§:** `15_DAKIKA_HIZLI_BASLANGIC.md`
- **DetaylÄ± rehber:** `TRAINING_DATA_REHBER.md`
- **Veri yol haritasÄ±:** `VERÄ°_TOPLAMA_YOL_HARÄ°TASI.md`
- **Durum kontrolÃ¼:** `python check_training_data.py`
- **Interaktif rehber:** `./baslangic_rehberi.sh`

---

## â“ SSS

### S: Hangi formatta olmalÄ±?
**C:** JPG, JPEG veya PNG. Tercihen JPG.

### S: Boyut ne olmalÄ±?
**C:** 500x500 ile 2000x2000 piksel arasÄ± ideal.

### S: AynÄ± gÃ¶rÃ¼ntÃ¼yÃ¼ her iki klasÃ¶re de koymalÄ± mÄ±yÄ±m?
**C:** HayÄ±r, gerek yok. Ä°sterseniz:
- `referans_gorseller/`: En iyi 5-10 gÃ¶rÃ¼ntÃ¼
- `training_data/`: TÃ¼m gÃ¶rÃ¼ntÃ¼ler (100+)

### S: Ä°ki klasÃ¶re de veri eklersem ne olur?
**C:** Hibrit sistem her ikisini de kullanÄ±r, daha iyi sonuÃ§ verir!

### S: Ã–nce hangisini doldurmalÄ±yÄ±m?
**C:** 
1. **HÄ±zlÄ± test iÃ§in:** `referans_gorseller/` (5-10 gÃ¶rÃ¼ntÃ¼)
2. **GerÃ§ek proje iÃ§in:** `training_data/` (100+ gÃ¶rÃ¼ntÃ¼)
3. **En iyi sonuÃ§ iÃ§in:** Ä°kisi birden

---

**âœ… Ã–ZET:** Evet, `training_data/` klasÃ¶rlerini doldurmanÄ±z gerekiyor. Her parÃ§a klasÃ¶rÃ¼ne en az 10-20 (ideal: 100+) gÃ¶rÃ¼ntÃ¼ ekleyin!

**ğŸš€ BaÅŸarÄ±lar!**
