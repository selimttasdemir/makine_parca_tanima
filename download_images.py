"""
Otomatik GÃ¶rÃ¼ntÃ¼ Ä°ndirici
Google Images'dan parÃ§a gÃ¶rÃ¼ntÃ¼lerini otomatik indirir
"""

import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urlencode
import time
from pathlib import Path


def google_image_search(query, num_images=10, output_dir='referans_gorseller'):
    """
    Google'dan gÃ¶rÃ¼ntÃ¼ ara ve indir
    
    NOT: google-images-download paketi artÄ±k Ã§alÄ±ÅŸmÄ±yor,
    bu basit alternatif yÃ¶ntemdir.
    """
    
    # Output klasÃ¶rÃ¼nÃ¼ oluÅŸtur
    os.makedirs(output_dir, exist_ok=True)
    
    # User agent
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    # Google Images URL
    params = {
        'q': query,
        'tbm': 'isch',
        'ijn': '0'
    }
    
    url = f"https://www.google.com/search?{urlencode(params)}"
    
    print(f"ğŸ” AranÄ±yor: {query}")
    print(f"   URL: {url}")
    
    try:
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # GÃ¶rÃ¼ntÃ¼ URL'lerini bul
        img_tags = soup.find_all('img')
        
        downloaded = 0
        for i, img in enumerate(img_tags[:num_images + 5]):  # Biraz fazla dene
            if downloaded >= num_images:
                break
                
            try:
                img_url = img.get('src') or img.get('data-src')
                
                if not img_url or img_url.startswith('data:'):
                    continue
                
                # GÃ¶rÃ¼ntÃ¼yÃ¼ indir
                img_response = requests.get(img_url, timeout=10)
                
                if img_response.status_code == 200:
                    filename = os.path.join(output_dir, f"{query.replace(' ', '_')}_{downloaded+1}.jpg")
                    
                    with open(filename, 'wb') as f:
                        f.write(img_response.content)
                    
                    print(f"   âœ“ Ä°ndirildi: {filename}")
                    downloaded += 1
                    
                    time.sleep(0.5)  # Rate limiting
                    
            except Exception as e:
                continue
        
        print(f"âœ… {downloaded} gÃ¶rÃ¼ntÃ¼ indirildi\n")
        return downloaded
        
    except Exception as e:
        print(f"âŒ Hata: {e}\n")
        return 0


def bulk_download(parcalar, images_per_parca=10):
    """Toplu indirme"""
    
    print("=" * 60)
    print("ğŸ“¥ TOPLU GÃ–RÃœNTÃœ Ä°NDÄ°RME BAÅLIYOR")
    print("=" * 60 + "\n")
    
    toplam = 0
    
    for parca in parcalar:
        # KlasÃ¶r oluÅŸtur
        parca_dir = os.path.join('referans_gorseller', parca)
        os.makedirs(parca_dir, exist_ok=True)
        
        # Ä°ngilizce arama terimleri ekle
        queries = [
            f"makine {parca}",
            f"mechanical {parca}",
            f"{parca} part"
        ]
        
        parca_toplam = 0
        
        for query in queries:
            count = google_image_search(
                query, 
                num_images=images_per_parca // len(queries), 
                output_dir=parca_dir
            )
            parca_toplam += count
            
            if parca_toplam >= images_per_parca:
                break
        
        toplam += parca_toplam
        print(f"ğŸ“Š {parca}: {parca_toplam} gÃ¶rÃ¼ntÃ¼\n")
    
    print("=" * 60)
    print(f"âœ… TOPLAM {toplam} GÃ–RÃœNTÃœ Ä°NDÄ°RÄ°LDÄ°")
    print("=" * 60)


def alternatif_yontem():
    """
    Alternatif: Manuel indirme talimatlarÄ±
    """
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  ğŸ–¼ï¸  MANUEL GÃ–RÃœNTÃœ Ä°NDÄ°RME REHBERÄ°                        â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    YÃ–NTEM 1: Google GÃ¶rseller (En Kolay)
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Google'da "makine vida" ara
    2. "GÃ¶rseller" sekmesine tÄ±kla
    3. Her gÃ¶rÃ¼ntÃ¼ye saÄŸ tÄ±k â†’ "Resmi farklÄ± kaydet"
    4. referans_gorseller/vida/ klasÃ¶rÃ¼ne kaydet
    5. 5-10 farklÄ± gÃ¶rÃ¼ntÃ¼ indir
    
    YÃ–NTEM 2: Ãœcretsiz Stok FotoÄŸraf Siteleri
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ Unsplash.com - search "mechanical parts"
    â€¢ Pexels.com - search "machine parts"
    â€¢ Pixabay.com - search "screw bolt nut"
    â€¢ Freepik.com - bazÄ± Ã¼cretsiz
    
    YÃ–NTEM 3: ÃœrÃ¼n KataloglarÄ±
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â€¢ McMaster-Carr (mcmaster.com)
    â€¢ Grainger (grainger.com)
    â€¢ RS Components (rs-online.com)
    
    YÃ–NTEM 4: Telefon KameranÄ±z
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1. Beyaz kaÄŸÄ±t Ã¼zerine parÃ§ayÄ± koy
    2. Ä°yi aydÄ±nlatma altÄ±nda Ã§ek
    3. 3-5 farklÄ± aÃ§Ä±dan
    4. Bilgisayara aktar
    
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  ğŸ“ HEDEF KLASÃ–R YAPISI                                      â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    referans_gorseller/
    â”œâ”€â”€ vida/
    â”‚   â”œâ”€â”€ vida1.jpg
    â”‚   â”œâ”€â”€ vida2.jpg
    â”‚   â”œâ”€â”€ vida3.jpg
    â”‚   â”œâ”€â”€ vida4.jpg
    â”‚   â””â”€â”€ vida5.jpg
    â”œâ”€â”€ somun/
    â”‚   â”œâ”€â”€ somun1.jpg
    â”‚   â””â”€â”€ ...
    â””â”€â”€ ...
    
    âœ… HER PARÃ‡A Ä°Ã‡Ä°N EN AZ 5 GÃ–RÃœNTÃœ HEDEF!
    """)


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘  ğŸ“¥ GÃ–RÃœNTÃœ Ä°NDÄ°RME ARACI                                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    UYARI: Otomatik web scraping bazÄ± sitelerde engellenir!
    En gÃ¼venilir yÃ¶ntem manuel indirmedir.
    
    SeÃ§enekler:
    1. Otomatik indirme dene (basit yÃ¶ntem)
    2. Manuel indirme talimatlarÄ±nÄ± gÃ¶ster
    """)
    
    secim = input("\nSeÃ§iminiz (1/2): ").strip()
    
    if secim == "1":
        parcalar = ['vida', 'somun', 'rulman', 'kayÄ±ÅŸ', 'diÅŸli', 
                   'piston', 'supap', 'krank mili', 'yay']
        
        print("\nâš ï¸  NOT: Bu basit scraper sÄ±nÄ±rlÄ± Ã§alÄ±ÅŸÄ±r.")
        print("Daha iyi sonuÃ§lar iÃ§in manuel indirme Ã¶nerilir!\n")
        
        devam = input("Devam edilsin mi? (e/h): ").strip().lower()
        
        if devam == 'e':
            bulk_download(parcalar, images_per_parca=5)
        else:
            print("Ä°ptal edildi.")
    
    elif secim == "2":
        alternatif_yontem()
    
    else:
        print("GeÃ§ersiz seÃ§im!")
    
    print("\nâœ… Ä°ÅŸlem tamamlandÄ±!")
    print("Sonraki adÄ±m: python test_system.py ile kontrol edin")
